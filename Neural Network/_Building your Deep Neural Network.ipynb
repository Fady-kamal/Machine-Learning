{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will build a deep neural network from scratch with as many layers as you want.\n",
    "\n",
    "<img src = \"https://i.imgur.com/p0Jv0Rq.png\" >\n",
    "\n",
    "<b>Neural Network</b> are built out of neural nets , originally inspired by human neurons but now simply an abstract computational tool. <b>Neural Network</b> is one of the best computational tool for large scale problems that offer sufficient data to learn features automatically as it is computationally cheap compared to tradional models.\n",
    "\n",
    "<br>\n",
    "\n",
    "# Outline\n",
    "\n",
    "* [Import Functions, and Libraries](#1)\n",
    "* [Helper Functions and Test cases and Test cases](#2)\n",
    "* [Initialization](#3)\n",
    " * [ 2-layer Neural Network](#3.1)\n",
    " * [L-Layer Model](#3.2)\n",
    "* [Forward propagation module](#4)\n",
    " * [Linear Forward For a Single Layer](#4.1)\n",
    " * [Linear-Activation Forward For a Single Layer](#4.2)\n",
    " * [linear Pass](#4.3)\n",
    " * [Cost Function](#5)\n",
    "* [Backward propagation module ](#6)\n",
    " * [Linear backward For a Single Layer](#6.1)\n",
    " * [Linear-Activation Backward For a Single Layer](#6.2)\n",
    " * [Backward Pass](#6.3)\n",
    " * [Update Parameters ](#6.4)\n",
    "* [Predict](#6.5)\n",
    "* [Print Mislabeled Images](#6.6)\n",
    "* [Application ](#7)\n",
    "  * [Load Data ](#7.1)\n",
    "  * [Split the Data Into Train And Test Sets](#7.2)\n",
    "  * [Architecture of The Model ](#7.3)\n",
    "   * [2-Layer Neural Network](#7.31)\n",
    "  * [Updating The Parameters ](#8)\n",
    "  * [Computing The Accuracy](#9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Functions, and Libraries <a anchor = \"anchor\" id = \"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import cv2 \n",
    "import os \n",
    "import random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions and Test cases  <a anchor = \"anchor\" id = \"2\"></a>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Helper Fuctions\n",
    "\n",
    "Helper Functions provide some important functions for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    '''\n",
    "    Usage:\n",
    "      #sigmoid --> computes the value of the sigmoid function given Z\n",
    "  \n",
    "    \n",
    "    Arguments:\n",
    "      #Z --> numpy array of any shape\n",
    "    \n",
    "    Returns:\n",
    "      #A --> the output of sigmoid(Z) with the same shape as Z\n",
    "      #cache --> returns Z as well but it useful during back propagation\n",
    "    '''\n",
    "    \n",
    "    A = 1/(1+ np.exp(-Z))\n",
    "    \n",
    "    cache = Z \n",
    "    \n",
    "    return A, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "    '''\n",
    "    Usage:\n",
    "      #sigmoid_backward --> used to implement the backward propagation for a single sigmoid unit.\n",
    "  \n",
    "    \n",
    "    Arguments:\n",
    "      #dA --> post-activation gradient, of any shape\n",
    "      #cache --> 'Z' where we store for computing backward propagation efficiently\n",
    "    \n",
    "    Returns:\n",
    "      #dZ --> gradient of the cost with respect to Z\n",
    "    '''\n",
    "    Z = cache \n",
    "    \n",
    "    s = 1 / (1 + np.exp(-Z))\n",
    "    dZ = dA * (1 - s) * s\n",
    "    \n",
    "    #if the condition is false , the assert function will stop the program and throw an assertion error\n",
    "    assert(dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    '''\n",
    "    Usage:\n",
    "      #relu --> computes the value of the ReLU function given Z\n",
    "  \n",
    "    \n",
    "    Arguments:\n",
    "      #Z --> an output of the linear layer, of any shape\n",
    "    \n",
    "    Returns:\n",
    "      #A --> the output of relu(Z) with the same shape as Z\n",
    "      #cache --> a python dictionary containing \"A\" which is  useful during back propagation\n",
    "    '''\n",
    "    \n",
    "    A = np.maximum(Z,0)\n",
    "    \n",
    "    #if the condition is false , the assert function will stop the program and throw an assertion error\n",
    "    assert(A.shape == Z.shape)\n",
    "    \n",
    "    cache = Z\n",
    "    \n",
    "    return A, Z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    '''\n",
    "    Usage:\n",
    "      #relu_backward --> used to implement the backward propagation for a single RELU unit.\n",
    "  \n",
    "    \n",
    "    Arguments:\n",
    "      #dA --> post-activation gradient, of any shape\n",
    "      #cache --> 'Z' where we store for computing backward propagation efficiently\n",
    "    \n",
    "    Returns:\n",
    "      #dZ --> gradient of the cost with respect to Z\n",
    "    '''\n",
    "    \n",
    "    Z = cache\n",
    "    \n",
    "    #convert dZ to a correct object \n",
    "    dZ = np.array(dA)\n",
    "    \n",
    "    # When z <= 0, you should set dz to 0 as well.\n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    #if the condition is false , the assert function will stop the program and throw an assertion error\n",
    "    assert(dZ.shape == Z.shape)\n",
    "    \n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Cases\n",
    "\n",
    "Test Cases provide some test cases to assess the correctness of your functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward_test_case():\n",
    "    np.random.seed(1)\n",
    "    \"\"\"\n",
    "    X = np.array([[-1.02387576, 1.12397796],\n",
    " [-1.62328545, 0.64667545],\n",
    " [-1.74314104, -0.59664964]])\n",
    "    W = np.array([[ 0.74505627, 1.97611078, -1.24412333]])\n",
    "    b = np.array([[1]])\n",
    "    \"\"\"\n",
    "    A = np.random.randn(3,2)\n",
    "    W = np.random.randn(1,3)\n",
    "    b = np.random.randn(1,1)\n",
    "    \n",
    "    return A, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward_test_case():\n",
    "    \"\"\"\n",
    "    X = np.array([[-1.02387576, 1.12397796],\n",
    " [-1.62328545, 0.64667545],\n",
    " [-1.74314104, -0.59664964]])\n",
    "    W = np.array([[ 0.74505627, 1.97611078, -1.24412333]])\n",
    "    b = 5\n",
    "    \"\"\"\n",
    "    np.random.seed(2)\n",
    "    A_prev = np.random.randn(3,2)\n",
    "    W = np.random.randn(1,3)\n",
    "    b = np.random.randn(1,1)\n",
    "    return A_prev, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward_test_case():\n",
    "    \"\"\"\n",
    "    X = np.array([[-1.02387576, 1.12397796],\n",
    " [-1.62328545, 0.64667545],\n",
    " [-1.74314104, -0.59664964]])\n",
    "    parameters = {'W1': np.array([[ 1.62434536, -0.61175641, -0.52817175],\n",
    "        [-1.07296862,  0.86540763, -2.3015387 ]]),\n",
    " 'W2': np.array([[ 1.74481176, -0.7612069 ]]),\n",
    " 'b1': np.array([[ 0.],\n",
    "        [ 0.]]),\n",
    " 'b2': np.array([[ 0.]])}\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    X = np.random.randn(4,2)\n",
    "    W1 = np.random.randn(3,4)\n",
    "    b1 = np.random.randn(3,1)\n",
    "    W2 = np.random.randn(1,3)\n",
    "    b2 = np.random.randn(1,1)\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return X, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_test_case():\n",
    "    Y = np.asarray([[1, 1, 1]])\n",
    "    aL = np.array([[.8,.9,0.4]])\n",
    "    \n",
    "    return Y, aL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward_test_case():\n",
    "    \"\"\"\n",
    "    z, linear_cache = (np.array([[-0.8019545 ,  3.85763489]]), (np.array([[-1.02387576,  1.12397796],\n",
    "       [-1.62328545,  0.64667545],\n",
    "       [-1.74314104, -0.59664964]]), np.array([[ 0.74505627,  1.97611078, -1.24412333]]), np.array([[1]]))\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    dZ = np.random.randn(1,2)\n",
    "    A = np.random.randn(3,2)\n",
    "    W = np.random.randn(1,3)\n",
    "    b = np.random.randn(1,1)\n",
    "    linear_cache = (A, W, b)\n",
    "    return dZ, linear_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward_test_case():\n",
    "    \"\"\"\n",
    "    aL, linear_activation_cache = (np.array([[ 3.1980455 ,  7.85763489]]), ((np.array([[-1.02387576,  1.12397796], [-1.62328545,  0.64667545], [-1.74314104, -0.59664964]]), np.array([[ 0.74505627,  1.97611078, -1.24412333]]), 5), np.array([[ 3.1980455 ,  7.85763489]])))\n",
    "    \"\"\"\n",
    "    np.random.seed(2)\n",
    "    dA = np.random.randn(1,2)\n",
    "    A = np.random.randn(3,2)\n",
    "    W = np.random.randn(1,3)\n",
    "    b = np.random.randn(1,1)\n",
    "    Z = np.random.randn(1,2)\n",
    "    linear_cache = (A, W, b)\n",
    "    activation_cache = Z\n",
    "    linear_activation_cache = (linear_cache, activation_cache)\n",
    "    \n",
    "    return dA, linear_activation_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward_test_case():\n",
    "    \"\"\"\n",
    "    X = np.random.rand(3,2)\n",
    "    Y = np.array([[1, 1]])\n",
    "    parameters = {'W1': np.array([[ 1.78862847,  0.43650985,  0.09649747]]), 'b1': np.array([[ 0.]])}\n",
    "    aL, caches = (np.array([[ 0.60298372,  0.87182628]]), [((np.array([[ 0.20445225,  0.87811744],\n",
    "           [ 0.02738759,  0.67046751],\n",
    "           [ 0.4173048 ,  0.55868983]]),\n",
    "    np.array([[ 1.78862847,  0.43650985,  0.09649747]]),\n",
    "    np.array([[ 0.]])),\n",
    "   np.array([[ 0.41791293,  1.91720367]]))])\n",
    "   \"\"\"\n",
    "    np.random.seed(3)\n",
    "    AL = np.random.randn(1, 2)\n",
    "    Y = np.array([[1, 0]])\n",
    "\n",
    "    A1 = np.random.randn(4,2)\n",
    "    W1 = np.random.randn(3,4)\n",
    "    b1 = np.random.randn(3,1)\n",
    "    Z1 = np.random.randn(3,2)\n",
    "    linear_cache_activation_1 = ((A1, W1, b1), Z1)\n",
    "\n",
    "    A2 = np.random.randn(3,2)\n",
    "    W2 = np.random.randn(1,3)\n",
    "    b2 = np.random.randn(1,1)\n",
    "    Z2 = np.random.randn(1,2)\n",
    "    linear_cache_activation_2 = ((A2, W2, b2), Z2)\n",
    "\n",
    "    caches = (linear_cache_activation_1, linear_cache_activation_2)\n",
    "\n",
    "    return AL, Y, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters_test_case():\n",
    "    \"\"\"\n",
    "    parameters = {'W1': np.array([[ 1.78862847,  0.43650985,  0.09649747],\n",
    "        [-1.8634927 , -0.2773882 , -0.35475898],\n",
    "        [-0.08274148, -0.62700068, -0.04381817],\n",
    "        [-0.47721803, -1.31386475,  0.88462238]]),\n",
    " 'W2': np.array([[ 0.88131804,  1.70957306,  0.05003364, -0.40467741],\n",
    "        [-0.54535995, -1.54647732,  0.98236743, -1.10106763],\n",
    "        [-1.18504653, -0.2056499 ,  1.48614836,  0.23671627]]),\n",
    " 'W3': np.array([[-1.02378514, -0.7129932 ,  0.62524497],\n",
    "        [-0.16051336, -0.76883635, -0.23003072]]),\n",
    " 'b1': np.array([[ 0.],\n",
    "        [ 0.],\n",
    "        [ 0.],\n",
    "        [ 0.]]),\n",
    " 'b2': np.array([[ 0.],\n",
    "        [ 0.],\n",
    "        [ 0.]]),\n",
    " 'b3': np.array([[ 0.],\n",
    "        [ 0.]])}\n",
    "    grads = {'dW1': np.array([[ 0.63070583,  0.66482653,  0.18308507],\n",
    "        [ 0.        ,  0.        ,  0.        ],\n",
    "        [ 0.        ,  0.        ,  0.        ],\n",
    "        [ 0.        ,  0.        ,  0.        ]]),\n",
    " 'dW2': np.array([[ 1.62934255,  0.        ,  0.        ,  0.        ],\n",
    "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
    "        [ 0.        ,  0.        ,  0.        ,  0.        ]]),\n",
    " 'dW3': np.array([[-1.40260776,  0.        ,  0.        ]]),\n",
    " 'da1': np.array([[ 0.70760786,  0.65063504],\n",
    "        [ 0.17268975,  0.15878569],\n",
    "        [ 0.03817582,  0.03510211]]),\n",
    " 'da2': np.array([[ 0.39561478,  0.36376198],\n",
    "        [ 0.7674101 ,  0.70562233],\n",
    "        [ 0.0224596 ,  0.02065127],\n",
    "        [-0.18165561, -0.16702967]]),\n",
    " 'da3': np.array([[ 0.44888991,  0.41274769],\n",
    "        [ 0.31261975,  0.28744927],\n",
    "        [-0.27414557, -0.25207283]]),\n",
    " 'db1': 0.75937676204411464,\n",
    " 'db2': 0.86163759922811056,\n",
    " 'db3': -0.84161956022334572}\n",
    "    \"\"\"\n",
    "    np.random.seed(2)\n",
    "    W1 = np.random.randn(3,4)\n",
    "    b1 = np.random.randn(3,1)\n",
    "    W2 = np.random.randn(1,3)\n",
    "    b2 = np.random.randn(1,1)\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    np.random.seed(3)\n",
    "    dW1 = np.random.randn(3,4)\n",
    "    db1 = np.random.randn(3,1)\n",
    "    dW2 = np.random.randn(1,3)\n",
    "    db2 = np.random.randn(1,1)\n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return parameters, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward_test_case_2hidden():\n",
    "    np.random.seed(6)\n",
    "    X = np.random.randn(5,4)\n",
    "    W1 = np.random.randn(4,5)\n",
    "    b1 = np.random.randn(4,1)\n",
    "    W2 = np.random.randn(3,4)\n",
    "    b2 = np.random.randn(3,1)\n",
    "    W3 = np.random.randn(1,3)\n",
    "    b3 = np.random.randn(1,1)\n",
    "  \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return X, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_grads(grads):\n",
    "    print (\"dW1 = \"+ str(grads[\"dW1\"]))\n",
    "    print (\"db1 = \"+ str(grads[\"db1\"]))\n",
    "    print (\"dA1 = \"+ str(grads[\"dA1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Initialization  <a anchor = \"anchor\" id = \"3\"></a>\n",
    "\n",
    "You will write two helper functions that will initialize the parameters for your model. The first function will be used to initialize parameters for a two layer model. The second one will generalize this initialization process to $L$ layers.\n",
    "\n",
    "## 2-layer Neural Network <a anchor = \"anchor\" id = \"3.1\"></a>\n",
    "\n",
    "\n",
    "the structure of the model: \n",
    "$$ Linear \\to  ReLU \\to  Linear \\to Sigmoid$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    '''\n",
    "    Usage:\n",
    "      #intialize_parameters --> used to randomly initialize the parameters of 2-Layer neural network\n",
    "  \n",
    "    \n",
    "    Arguments:\n",
    "      #n_x --> the size of the input layer \n",
    "      #n_h --> the size of the hidden layer\n",
    "      #n_y --> the size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "      #parameters -->  python dictionary containing your parameters:\n",
    "                       W1 -- weight matrix of shape (n_h, n_x)\n",
    "                       b1 -- bias vector of shape (n_h, 1)\n",
    "                       W2 -- weight matrix of shape (n_y, n_h)\n",
    "                       b2 -- bias vector of shape (n_y, 1)\n",
    "    '''\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    #Randomly initialize the parameters\n",
    "    W1 = np.random.randn(n_h, n_x) * 0.001\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h) * 0.001\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "    \n",
    "    #if one of the conditions is false , the assert function will stop the program and throw an assertion error\n",
    "    assert(W1.shape == (n_h, n_x))\n",
    "    assert(b1.shape == (n_h, 1))\n",
    "    assert(W2.shape == (n_y, n_h))\n",
    "    assert(b2.shape == (n_y, 1))\n",
    "    \n",
    "    \n",
    "    #compute the parameters\n",
    "    parameters = {\"W1\": W1, \"b1\":b1 , \"W2\": W2, \"b2\":b2}\n",
    "    \n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[ 0.01624345 -0.00611756 -0.00528172]\n",
      " [-0.01072969  0.00865408 -0.02301539]]\n",
      "b1 = [[0.]\n",
      " [0.]]\n",
      "W2 = [[ 0.01744812 -0.00761207]]\n",
      "b2 [[0.]]\n"
     ]
    }
   ],
   "source": [
    "#Test our code \n",
    "parameters = initialize_parameters(3,2,1)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "## L-Layer Model <a anchor = \"anchor\" id = \"3.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    '''\n",
    "    Usage:\n",
    "      #intialize_parameters_deep --> used to randomly initialize the parameters of L-Layer neural network\n",
    "  \n",
    "    \n",
    "    Arguments:\n",
    "      #layer_dims --> list containing each dimension for each layer \n",
    "    \n",
    "    Returns:\n",
    "      #parameters -->  python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                       Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                       bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    '''\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    \n",
    "    #iniatialize empty dic which will be populated later\n",
    "    parameters = {} \n",
    "    \n",
    "    #define the number of layers in our network \n",
    "    L = len(layer_dims)\n",
    "    \n",
    "    \n",
    "    for l in range(1, L):\n",
    "        \n",
    "        parameters[\"W\" + str(l)] = np.random.randn(layer_dims[l] , layer_dims[l - 1]) * 0.01\n",
    "        parameters[\"b\" + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "      \n",
    "        \n",
    "        #if one of the conditions is false , the assert function will stop the program and throw an assertion error\n",
    "        assert(parameters[\"W\" + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters[\"b\" + str(l)].shape == (layer_dims[l], 1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return parameters    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1[[ 0.01788628  0.0043651   0.00096497 -0.01863493 -0.00277388]\n",
      " [-0.00354759 -0.00082741 -0.00627001 -0.00043818 -0.00477218]\n",
      " [-0.01313865  0.00884622  0.00881318  0.01709573  0.00050034]\n",
      " [-0.00404677 -0.0054536  -0.01546477  0.00982367 -0.01101068]]\n",
      "b1[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "W2[[-0.01185047 -0.0020565   0.01486148  0.00236716]\n",
      " [-0.01023785 -0.00712993  0.00625245 -0.00160513]\n",
      " [-0.00768836 -0.00230031  0.00745056  0.01976111]]\n",
      "b2[[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "#Test the code\n",
    "parameters = initialize_parameters_deep([5,4,3])\n",
    "\n",
    "print(\"W1\" + str(parameters[\"W1\"]))\n",
    "print(\"b1\" + str(parameters[\"b1\"]))\n",
    "print(\"W2\" + str(parameters[\"W2\"]))\n",
    "print(\"b2\" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Forward propagation module <a anchor = \"anchor\" id = \"4\"> </a>\n",
    "\n",
    "<img src = \"https://i.imgur.com/OIAYrns.png\" style = \"width: 80%;\">\n",
    "\n",
    "The term <b>Forward</b> means that we are moving forward in our computational graph to compute every operation in it. \n",
    "\n",
    "The term <b> Propagation </b> means that we compute the next operation (inside the next node) using the output of the previous as an input. \n",
    "\n",
    "So the forward propagation is just forward pass of a computational graph where we applay each operation from left to right, passing the outputs of each operation as the input to the next node. \n",
    "\n",
    "The Forward Propagation consists of two parts: \n",
    " * <b> Linear Part: </b>  in this part, we compute the weighted input of the layer $l$, $Z^{[l]}$\n",
    " * <b> Activation Part: </b> in this part, we compute the activation of the weighted input of the layer $l$, $A^{[l]}$\n",
    " \n",
    "\n",
    " \n",
    " \n",
    " \n",
    " <br>\n",
    " \n",
    " \n",
    " ## Linear Forward For a Single Layer<a anchor  = \"anchor\" id = \"4.1\"> </a>\n",
    " \n",
    " In this section , we compute the weighted input for the activation which is:  $$Z^{[l]} = W^{[l]} A^{[l - 1]}  + b^ {[l]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    '''\n",
    "    Usage:\n",
    "      #inear_forward --> used to compute the weighted input, Z\n",
    "  \n",
    "    \n",
    "    Arguments:\n",
    "      #A --> activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "      #W --> weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "      #b --> bias vector, numpy array of shape (size of the current layer, 1) \n",
    "    \n",
    "    Returns:\n",
    "      #Z --> the weighted input, aslo called pre-activation parameter\n",
    "      #cache --> tuple of values (A, W, b) which is useful for  backpropagation step \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    Z = np.matmul(W,A) + b\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    \n",
    "    cache = (A,W,b)\n",
    "    \n",
    "    return Z, cache "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.62434536 -0.61175641]\n",
      " [-0.52817175 -1.07296862]\n",
      " [ 0.86540763 -2.3015387 ]] \n",
      "\n",
      " [[ 1.74481176 -0.7612069   0.3190391 ]] \n",
      "\n",
      " [[-0.24937038]]\n",
      "\n",
      "\n",
      "Z = [[ 3.26295337 -1.23429987]]\n"
     ]
    }
   ],
   "source": [
    "#Test the code \n",
    "A,W,b = linear_forward_test_case()\n",
    "\n",
    "print(f\"{A} \\n\\n {W} \\n\\n {b}\\n\\n\") \n",
    "\n",
    "Z, linear_cache = linear_forward(A, W, b)\n",
    "\n",
    "print(\"Z = \" + str(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Linear-Activation Forward For a Single Layer <a anchor = \"anchor\" id = \"4.2\"></a>\n",
    "\n",
    "In this section , we compute the activation of the weighted input which is defined as: $$A^{[l]} = g^{[l]} (Z^{[l]})$$\n",
    "\n",
    "### Types of Activation Functions: \n",
    "\n",
    "- Sigmoid Function \n",
    " \n",
    " <img src = \"https://i.imgur.com/pAFKTa5.png\" >\n",
    " \n",
    "  The sigmoid function takes a real value and maps it to the range  between $0$ and $1$. \n",
    " \n",
    "  The sigmoid function, using vector notation,  is defined as: $$\\sigma(Z) = \\sigma(W A + b) = \\frac{1} {1 + \\exp{ - ( W A + b)   }} $$\n",
    "\n",
    "  The sigmoid funtion has a number of advantages: \n",
    "  * It maps the output in the range between $0$ and $1$, which is useful in squashing outliers toward $0$ and $1$\n",
    "  * It's differentiable , which will be very useful mathematically for learning \n",
    "  \n",
    "  \n",
    "  <br>\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "- ReLu\n",
    "\n",
    "  <img src = \"https://i.imgur.com/NvJ2zt9.png\" >\n",
    "\n",
    "  ReLU is an acornym formed from the intials of \"Rectified Linear Unit\" , and it's  is the simplest and most commonly used       activation function. It takes an input and return the same input if it's positive and zero otherwise.\n",
    "\n",
    "  The ReLU function, using vector notation,  is defined as: $$ReLU(Z) = max(Z,0)$$\n",
    " \n",
    "  The ReLU function has a number of advantages:\n",
    "  \n",
    "   - it's close to linear, ulike the sigmoid function which for high value of Z , results in values of y which are saturated \n",
    "     which has bad results for learning \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    '''\n",
    "    Usage:\n",
    "      #inear_activation_forward --> used to compute the activation of the weighted input \n",
    "  \n",
    "    \n",
    "    Arguments:\n",
    "      #A_prev --> activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "      #W --> weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "      #b --> bias vector, numpy array of shape (size of the current layer, 1)\n",
    "      #activation --> a string represents the type of the activation function used in this layer\n",
    "    \n",
    "    Returns:\n",
    "      #A --> the output of the activation function, also called post-activation value\n",
    "      #cache --> a tuple linear cache values with the activation cache --> (A_prev , W, b, Z) which  is useful for backpropagation\n",
    "    '''\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With sigmoid: \n",
      " The pos-activation value: [[0.96890023 0.11013289]] \n",
      " Cache: ((array([[-0.41675785, -0.05626683],\n",
      "       [-2.1361961 ,  1.64027081],\n",
      "       [-1.79343559, -0.84174737]]), array([[ 0.50288142, -1.24528809, -1.05795222]]), array([[-0.90900761]])), array([[ 3.43896131, -2.08938436]]))\n",
      "\n",
      "\n",
      "With relu: \n",
      " The pos-activation value: [[3.43896131 0.        ]] \n",
      " Cache: ((array([[-0.41675785, -0.05626683],\n",
      "       [-2.1361961 ,  1.64027081],\n",
      "       [-1.79343559, -0.84174737]]), array([[ 0.50288142, -1.24528809, -1.05795222]]), array([[-0.90900761]])), array([[ 3.43896131, -2.08938436]]))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test the code \n",
    "A_prev, W, b = linear_activation_forward_test_case()\n",
    "\n",
    "A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = \"sigmoid\")\n",
    "print(f\"With sigmoid: \\n The pos-activation value: {A} \\n Cache: {linear_activation_cache}\\n\\n\")\n",
    "\n",
    "A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = \"relu\")\n",
    "print(f\"With relu: \\n The pos-activation value: {A} \\n Cache: {linear_activation_cache}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Pass <a anchor = \"anchor\" id = \"4.3\"></a>\n",
    " \n",
    "<b>The pseudo-code of the  algorithm for computing the forward step in L-layer feedforward network, given the input matrix $A^{[0]}$ is:</b>\n",
    " \n",
    " <i><b>for</b></i> $ \\hspace{1mm} l \\hspace{1mm} from \\hspace{1mm} 1 \\hspace{1mm} to \\hspace{1mm} L:\\\\\n",
    " \\hspace{1cm} Z^{[l]} = W^{[l]} A^{[l - 1]}  + b^ {[l]} \\\\\n",
    "  \\hspace{1cm} A^{[l]} = g^{[l]} (Z^{[l]}) \\\\\n",
    "\\hspace{-6mm}\\hat{y} = A^{[L]}   \n",
    " $\n",
    " \n",
    "<b>When we implement the forward pass:</b>\n",
    " - we use ReLU for intermediate layers \n",
    " - we use Sigmoid for output layer\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    '''\n",
    "    Usage:\n",
    "      #L_model_forward --> used to implement the forward pass\n",
    "  \n",
    "    \n",
    "    Arguments:\n",
    "      #X --> numpy array of shape (input size , number of examples)\n",
    "      #parameters --> python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                      Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                      bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \n",
    "    Returns:\n",
    "      #AL --> last-post activation value\n",
    "      #caches --> list of tuples where each tuples represents --> (linear_cache , activation_cache) \n",
    "                  corresponding to a certain layer\n",
    "    '''\n",
    "    \n",
    "    #initialize an empty list which will contains all the caches corresponding to each layer\n",
    "    caches = []\n",
    "    \n",
    "    #define the input array \n",
    "    A = X\n",
    "    \n",
    "    #define the number of layers of the neural network  --> # items in dic (parameters) / 2\n",
    "    #since each layer has two parameters W, b \n",
    "    L  = len(parameters) // 2\n",
    "    \n",
    "    #Set the ReLU activation function  to all the layers except the final layer\n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "    \n",
    "        A, cache = linear_activation_forward(A_prev, parameters[\"W\" + str(l)],\n",
    "                                              parameters[\"b\" + str(l)],\n",
    "                                              activation = \"relu\")\n",
    "        caches.append(cache)\n",
    "        \n",
    "    \n",
    "    #Set the sigmoid activation funtion to the final layer\n",
    "    AL, cache = linear_activation_forward(A, parameters[\"W\" + str(L)],\n",
    "                                              parameters[\"b\" + str(L)],\n",
    "                                              activation = \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    \n",
    "    assert(AL.shape == (1, X.shape[1]))\n",
    "    \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL = [[0.17007265 0.2524272 ]]\n",
      "Length of caches list = 2\n"
     ]
    }
   ],
   "source": [
    "#Test the code\n",
    "X, parameters = L_model_forward_test_case()\n",
    "AL, caches = L_model_forward(X, parameters)\n",
    "print(\"AL = \" + str(AL))\n",
    "print(\"Length of caches list = \" + str(len(caches)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Cost Function <a anchor = \"anchor\" id  = \"5\" ></a>\n",
    "\n",
    "We want a Cost function that models the  distance between the actual output and the estimated  one. It's common to use cross-entropy as a cost funtction.\n",
    "\n",
    "The Cross-Entropy is defined as:\n",
    "\n",
    "$$Cost = -\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(a^{[L] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right)) \\tag{7}$$ \n",
    "\n",
    "The vector notation of the cost function using <b>Hadamard Product</b> is defined as:\n",
    "\n",
    "$$ Cost = -\\frac{1}{m} \\sum {Y \\odot \\log(A^{[L]}) + (1 - Y) \\odot \\log( 1 - A^{[L]})}$$\n",
    "\n",
    "$\\sum:$ means that we will sum the output of all the entities of the output vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL,Y):\n",
    "    '''\n",
    "    Usage:\n",
    "      #compute_cost --> used to implement the forward pass\n",
    "  \n",
    "    \n",
    "    Arguments:\n",
    "      #AL --> probability vector corresponding to your label predictions, shape (1, number of examples)\n",
    "      #Y --> true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "      #AL --> last-post activation value\n",
    "      #caches --> list of tuples where each tuples represents --> (linear_cache , activation_cache) \n",
    "                  corresponding to a certain layer\n",
    "    '''\n",
    "    #get the number of the training examples\n",
    "    m = Y.shape[1] \n",
    "    \n",
    "    #compute the cost\n",
    "    cost = (-1/m) * np.sum(np.multiply(Y, np.log(AL)) + np.multiply((1 - Y ), ( 1 - np.log( 1 - AL))))\n",
    "    #cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
    "    \n",
    "    #reduce the rank of the array to be zero instead of one \n",
    "    #in other words, covenrt one-rank array to scalar (zero-rank array) --> ((e.g. this turns [17] into 17))\n",
    "    cost = np.squeeze(cost)\n",
    "    \n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 0.41493159961539694\n"
     ]
    }
   ],
   "source": [
    "#Test the code \n",
    "Y, AL = compute_cost_test_case()\n",
    "print(\"cost = \" + str(compute_cost(AL, Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "# Backward propagation module <a anchor = \"anchor\" id = \"6\" ></a>\n",
    "\n",
    "<img src = \"https://i.imgur.com/tKqQ4Uc.png\" style = \"width: 80%;\"> \n",
    "\n",
    "<br>\n",
    "\n",
    "In the backward pass of a computational graph,  we applay each operation from right to left , passing the outputs of each operation as the input to the next node. So, we start from the final layer to the first one .\n",
    "\n",
    "## We have some equations used in backpropagation: \n",
    "\n",
    "<b> We define the error $\\delta^{[l]}_{j} $ of the neuron $j$ in layer $L$ as: </b>\n",
    "$$\\large \\delta^{[l]}_{j} = \\frac{\\partial{J}} { \\partial{z^{[l]}_{j}} } \\tag{1} $$\n",
    "\n",
    "<b> We can also compute the error using another fomulas which is: </b>\n",
    "$$ \\large \\delta^{[l]}_{j} = \\frac{\\partial{J}} { \\partial{a^{[l]}_{j}} }   \\sigma^\\prime (z^{[l]}_{j}) \\tag{2} $$\n",
    "\n",
    "<b>We can rewrite the second formula using vector notation: </b>\n",
    "$$ \\large \\delta^{[l]} = \\nabla_a {J} \\odot \\sigma^\\prime (z^{[l]})  \\tag{3} $$\n",
    "\n",
    "<b>There's a enquation that describe the error $\\delta^{[l]}$ in terms of the error in the next layer $\\delta^{[l]} $ which is defined as:</b>\n",
    " $$\\large \\delta^{[l]} = \\big((W^{l + 1})^T  \\delta^{[l + 1]}  \\big) \\odot \\sigma^\\prime (z^{[l]})  \\tag{4}$$\n",
    " \n",
    " <b>There's an equation the describes the rate of change of the cost with respect to any weight in the\n",
    "network which is defined as: </b>\n",
    "\n",
    "$$ \\large  \\frac{\\partial{J}} { \\partial{w^{[l]}_{jk}} } = a^{[l  - 1]}_{k} \\delta^{[l]}_{j} \\tag{5}  $$\n",
    "\n",
    "<b> Where, </b> \n",
    " $w^{[l]}_{jk}: $ denotes the weight for the connection from the k-th neuron in\n",
    "the (l − 1)-th layer to the j-th neuron in the l-th layer\n",
    "\n",
    "\n",
    "<b> There's an equation for the rate of change of the cost with respect to any bias in the network which is defined as: </b>\n",
    "$$  \\large \\frac{\\partial{J}} { \\partial{b^{[l]}_{j}} } =  \\delta^{[l]}_{j} \\tag{6}$$\n",
    " \n",
    "\n",
    "\n",
    "Using these equations , we can compute the partial derivatives $ \\large \\frac{\\partial{J}} { \\partial{W} }$  and $ \n",
    "\\large \\frac{\\partial{J}} { \\partial{b} } $ of the\n",
    "cost function $\\large J$ with respect to any weight $W$ or bias $\\large b$ in the network. \n",
    "\n",
    "<br>\n",
    "\n",
    "## Linear backward For a Single Layer <a anchor = \"anchor\" id  = \"6.1\" ></a> \n",
    "In linear backward , we compute $\\large (dW^{[L]}, db^{[L]}, dA^{[L]})$ Using the weighted input $\\large dZ^{[L]}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    '''\n",
    "    Usage:\n",
    "      #linear_backward --> used to implement the linear portion of backward propagation for a single layer (layer l)\n",
    "  \n",
    "    \n",
    "    Arguments:\n",
    "      #dZ --> Gradient of the cost with respect to the linear output (of current layer l)\n",
    "      #cache --> tuple of values (A_prev, W, b) coming from the forward propagation in the current layer (Linear_cache)\n",
    "    \n",
    "    Returns:\n",
    "      #dA_prev --> Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "      #dW --> Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "      #db --> Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    '''\n",
    "    \n",
    "    A_prev , W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    #compute the linear portion of backward propagation \n",
    "    dW = 1/m * np.matmul(dZ, A_prev.T)\n",
    "    \n",
    "    # we keep dimension db so that the dimension doesn't change to 1-rank array bus stay column array \n",
    "    db = 1/m * np.sum(dZ, axis = 1 , keepdims = True)\n",
    "    dA_prev = np.matmul(W.T, dZ)\n",
    "    \n",
    "    assert(dA_prev.shape == A_prev.shape)\n",
    "    assert(dW.shape == W.shape)\n",
    "    assert(db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA_prev = [[ 0.51822968 -0.19517421]\n",
      " [-0.40506361  0.15255393]\n",
      " [ 2.37496825 -0.89445391]]\n",
      "dW = [[-0.10076895  1.40685096  1.64992505]]\n",
      "db = [[0.50629448]]\n"
     ]
    }
   ],
   "source": [
    "#Test the code \n",
    "dZ, linear_cache = linear_backward_test_case()\n",
    "\n",
    "dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "\n",
    "print(f\"dA_prev = {dA_prev}\")\n",
    "print(f\"dW = {dW}\")\n",
    "print(f\"db = {db}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear-Activation Backward For a Single Layer <a anchor  = \"anchor\" id = \"6.2\"></a>\n",
    "\n",
    "In this section, We $dZ$  with the help of computing the linear backward using the equation number $3$ from the previous equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    '''\n",
    "    Usage:\n",
    "      #inear_activation_backward --> used to implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "  \n",
    "    \n",
    "    Arguments:\n",
    "      #dA --> the post-activation gradient for the current layer L \n",
    "      #cache --> tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "      #activation --> a string represents the type of the activation function used in this layer\n",
    "    \n",
    "    Returns:\n",
    "      #dA_prev --> Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "      #dW --> Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "      #db --> Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    '''\n",
    "    \n",
    "    #Extract linear cache and activation cache from the tuple cache ((dA, W, b), (Z)) --> (dA, W, b), (Z)\n",
    "    linear_cache, activation_cache = cache \n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "\n",
    "        \n",
    "        \n",
    "    return dA_prev, dW, db "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid:\n",
      "dA_prev = [[ 0.11017994  0.01105339]\n",
      " [ 0.09466817  0.00949723]\n",
      " [-0.05743092 -0.00576154]]\n",
      "dW = [[ 0.10266786  0.09778551 -0.01968084]]\n",
      "db = [[-0.05729622]]\n",
      "\n",
      "relu:\n",
      "dA_prev = [[ 0.44090989  0.        ]\n",
      " [ 0.37883606  0.        ]\n",
      " [-0.2298228   0.        ]]\n",
      "dW = [[ 0.44513824  0.37371418 -0.10478989]]\n",
      "db = [[-0.20837892]]\n"
     ]
    }
   ],
   "source": [
    "#Test the code\n",
    "\n",
    "AL, linear_activation_cache = linear_activation_backward_test_case()\n",
    "\n",
    "dA_prev, dW, db = linear_activation_backward(AL, linear_activation_cache, activation = \"sigmoid\")\n",
    "print (\"sigmoid:\")\n",
    "print (\"dA_prev = \"+ str(dA_prev))\n",
    "print (\"dW = \" + str(dW))\n",
    "print (\"db = \" + str(db) + \"\\n\")\n",
    "\n",
    "dA_prev, dW, db = linear_activation_backward(AL, linear_activation_cache, activation = \"relu\")\n",
    "print (\"relu:\")\n",
    "print (\"dA_prev = \"+ str(dA_prev))\n",
    "print (\"dW = \" + str(dW))\n",
    "print (\"db = \" + str(db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Pass <a anchor = \"anchor\" id = \"6.3\" ></a>\n",
    "\n",
    "###  The Pseudo-code of the Backpropagation Algorithm (Involving feedforward step) is defined as:\n",
    "\n",
    " -  Given input $X = A^{[0]}$\n",
    " - Compute the forward step: \n",
    " \n",
    "  <i><b>for</b></i> $ \\hspace{1mm} l \\hspace{1mm} from \\hspace{1mm} 1 \\hspace{1mm} to \\hspace{1mm} L:\\\\\n",
    " \\hspace{1cm} Z^{[l]} = W^{[l]} A^{[l - 1]}  + b^ {[l]} \\\\\n",
    "  \\hspace{1cm} A^{[l]} = g^{[l]} (Z^{[l]}) \\\\\n",
    " \\hspace{-6mm}\\hat{y} = A^{[L]}   \n",
    " $\n",
    " \n",
    " \n",
    " - Compute the output error $ \\delta^{[L]} $ , then, compute the gradients of the cost function, $\\frac{\\partial{J}} { \\partial{W^{[L]}} }, \\frac{\\partial{J}} { \\partial{b^{[L]}} }$:\n",
    " \n",
    " $\\hspace{1cm}\\delta^{[L]} = \\nabla_a {J} \\odot \\sigma^\\prime (z^{[L]})\\\\\n",
    " \\hspace{1cm} \\frac{\\partial{J}} { \\partial{W^{[L]}} } = \\frac{1}{m} \\delta^{[L]}  \\big(A^{[L  - 1]}\\big)^T = \\frac{1}{m}\\frac{\\partial{J}} { \\partial{Z^{[L]}} } \\big(A^{[L  - 1]}\\big)^T \\\\\n",
    "  \\hspace{1cm} \\frac{\\partial{J}} { \\partial{b^{[L]}} } = \\frac{1}{m} \\sum_{i}^{m} {\\delta^{[L] (i)}} \\frac{1}{m} \\sum_{i}^{m} { \\big ( \\frac{\\partial{J}} { \\partial{Z^{[L]}} } \\big ) ^{(i)} }$\n",
    " \n",
    " \n",
    " - Backpropagate the error, then, compute the gradients of the cost function, $\\frac{\\partial{J}} { \\partial{W^{[l]}} }, \\frac{\\partial{J}} { \\partial{b^{[l]}} }$: \n",
    " \n",
    "    <i><b>for</b></i> $ \\hspace{1mm} l \\hspace{1mm} from \\hspace{1mm} L - 1 \\hspace{1mm} to \\hspace{1mm} 1:\\\\\n",
    " \\hspace{1cm} \\delta^{[l]} = \\frac{\\partial{J}} { \\partial{Z^{[l]}} } = \\big((W^{l + 1})^T  \\delta^{[l + 1]}  \\big) \\odot \\sigma^\\prime (z^{[l]}) \\\\\n",
    "  \\hspace{1cm} \\frac{\\partial{J}} { \\partial{W^{[l]}} } = \\frac{1}{m} \\delta^{[l]}  \\big(A^{[l  - 1]}\\big)^T = \\frac{1}{m}\\frac{\\partial{J}} { \\partial{Z^{[l]}} } \\big(A^{[l  - 1]}\\big)^T \\\\\n",
    "  \\hspace{1cm} \\frac{\\partial{J}} { \\partial{b^{[l]}} } = \\frac{1}{m} \\sum_{i}^{m} {\\delta^{[l] (i)}} \\frac{1}{m} \\sum_{i}^{m} { \\big ( \\frac{\\partial{J}} { \\partial{Z^{[l]}} } \\big ) ^{(i)} }\n",
    " $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    '''\n",
    "    Usage:\n",
    "      #L_model_backward --> used to implement the backward propagation setp for L-layer neural network.\n",
    "  \n",
    "    \n",
    "    Arguments:\n",
    "      #AL --> last-post activation value\n",
    "      #Y --> true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
    "      #caches --> list of tuples where each tuple represents --> (linear_cache , activation_cache) \n",
    "                  corresponding to a certain layer\n",
    "                  caches = [((A1, W1, b1), Z1), ((A2, W2, b2), Z2), ..... , ((AL, WL, bL), ZL)]\n",
    "    \n",
    "    Returns:\n",
    "      #grads -- A dictionary with the gradients\n",
    "                grads[\"dA\" + str(l)] = ... \n",
    "                grads[\"dW\" + str(l)] = ...\n",
    "                grads[\"db\" + str(l)] = ...\n",
    "    '''  \n",
    "    \n",
    "     \n",
    "    grads = {} #intialize the gradients dic\n",
    "    \n",
    "    L = len(caches) #define the number of layers\n",
    "    \n",
    "    m = AL.shape[1] #define the number of training examples\n",
    "    \n",
    "    #if Y doesn't have the shape of AL , make it.\n",
    "    #if not , do nothing \n",
    "    Y = Y.reshape(AL.shape)\n",
    "    \n",
    "    \n",
    "    #intializing the backporpagation\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y , 1 - AL))\n",
    "    \n",
    "    #get cache corresponding to the final layer\n",
    "    current_cache = caches[L - 1]\n",
    "    \n",
    "    #compute dW and db corresponding to the final layer, L \n",
    "    #also, compute the activation gradient of the previous layer using the current layer (final)\n",
    "    grads[\"dA\" + str(L - 1 )], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache,\n",
    "                                                                                                      \"sigmoid\")\n",
    "    \n",
    "    #Loop from the penultimate layer up til the first one \n",
    "    for l in reversed(range(L - 1)):\n",
    "        \n",
    "        current_cache = caches[l]\n",
    "        grads[\"dA\" + str(l)], grads[\"dW\" + str(l + 1)], grads[\"db\" + str(l + 1)] = linear_activation_backward(grads[\"dA\" + str(l + 1)],\n",
    "                                                                                                              current_cache,\n",
    "                                                                                                              \"relu\")\n",
    "    return grads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW1 = [[0.41010002 0.07807203 0.13798444 0.10502167]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.05283652 0.01005865 0.01777766 0.0135308 ]]\n",
      "db1 = [[-0.22007063]\n",
      " [ 0.        ]\n",
      " [-0.02835349]]\n",
      "dA1 = [[ 0.12913162 -0.44014127]\n",
      " [-0.14175655  0.48317296]\n",
      " [ 0.01663708 -0.05670698]]\n"
     ]
    }
   ],
   "source": [
    "AL, Y_assess, caches = L_model_backward_test_case()\n",
    "grads = L_model_backward(AL, Y_assess, caches)\n",
    "print_grads(grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Parameters <a anchor = \"anchor\" id = \"6.4\" ></a>\n",
    "<p style = \"font-size: 18px;\">The goal of updating the parameters is to find the parameters that minimize the cost function as much as possible. To minimize the cost function , we neead an optimization algorithm to do this job. One of the simplest algorithms to do this job is <b>Steepest Descent</b>.The classical steepest descent method is one of the oldest methods for the\n",
    "minimization of a general nonlinear function. The steepest descent method, also known as the gradient descent method, was first proposed by Cauchy in 1847 In the original paper, Cauchy proposed the use of the gradient as\n",
    "a way of solving a nonlinear equation of the form:\n",
    "$$f(x_1, x_2,\\ldots,x_n)=0, \\tag{1} $$\n",
    "    where $f$ is a real-valued continuous function that never becomes negative\n",
    "and which remains continuous, at least within certain limits. The basis\n",
    "for the method is the simple observation that a continuous function should\n",
    "decrease, at least initially, if one takes a step along the direction of the\n",
    "negative gradient. The only difficulty then is deciding how to choose the\n",
    "length of the step one should take. While this is easy to compute for special\n",
    "cases such as a convex quadratic function, the general case usually requires\n",
    "the minimization of the function in question along the negative gradient\n",
    "direction.</p>\n",
    "\n",
    "\n",
    "###  The formula of updating the parameters using gradient descent: \n",
    "$$ \\large b^{[l]} \\gets b^{[l]} - \\alpha \\frac{\\partial{J}} { \\partial{b^{[L]}} }\\\\\n",
    "\\normalsize W^{[l]} \\gets W^{[l]} -  \\alpha \\frac{\\partial{J}} { \\partial{W^{[L]}} }\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    '''\n",
    "    Usage:\n",
    "      #update_parameters --> used to update the parameters using  gradient descent \n",
    "  \n",
    "    \n",
    "    Arguments:\n",
    "      #parameters --> python dictionary containing your parameters \n",
    "      #grads --> python dictionary containing your gradients, output of L_model_backward\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "      #parameters --> python dictionary containing your updated parameters \n",
    "                      parameters[\"W\" + str(l)] = ... \n",
    "                      parameters[\"b\" + str(l)] = ...\n",
    "    '''\n",
    "    #define the number of layer \n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    #Updating the parameters of the network\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * grads[\"db\" + str(l + 1)]\n",
    "        \n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[-0.59562069 -0.09991781 -2.14584584  1.82662008]\n",
      " [-1.76569676 -0.80627147  0.51115557 -1.18258802]\n",
      " [-1.0535704  -0.86128581  0.68284052  2.20374577]]\n",
      "b1 = [[-0.04659241]\n",
      " [-1.28888275]\n",
      " [ 0.53405496]]\n",
      "W2 = [[-0.55569196  0.0354055   1.32964895]]\n",
      "b2 = [[-0.84610769]]\n"
     ]
    }
   ],
   "source": [
    "#Test the code\n",
    "parameters, grads = update_parameters_test_case()\n",
    "parameters = update_parameters(parameters, grads, 0.1)\n",
    "print (\"W1 = \"+ str(parameters[\"W1\"]))\n",
    "print (\"b1 = \"+ str(parameters[\"b1\"]))\n",
    "print (\"W2 = \"+ str(parameters[\"W2\"]))\n",
    "print (\"b2 = \"+ str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict  <a anchor = \"anchor\" id = \"6.5\" ></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,y, parameters):\n",
    "    '''\n",
    "    Usage:\n",
    "      #predict  --> used to used to predict the results of a  L-layer neural network.\n",
    "                    In other words, used to compute the accuracy of the model\n",
    "  \n",
    "    \n",
    "    Arguments:\n",
    "      #X -- data set of examples you would like to label\n",
    "      #parameters -- parameters of the trained model\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "      #accuracy --> predictions for the given dataset X (the accuracy of this model on that dataset)\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    \n",
    "    # Forward propagation\n",
    "    probs, caches = L_model_forward(X, parameters)\n",
    "    \n",
    "    #compute the accuracy \n",
    "    accuracy = float(np.sum((np.greater(probs, 0.5) == y))) / m\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Mislabeled Images <a anchor = \"anchor\" id = \"6.6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mislabeled_images(classes, x, y, p):\n",
    "    '''\n",
    "    Usage:\n",
    "      #print_mislabeled_images  --> used to used to Plots images where predictions and truth were different.l\n",
    "  \n",
    "    \n",
    "    Arguments:\n",
    "      #X --> data set of examples you would like to label\n",
    "      #y --> true labels\n",
    "      #p --> predictions (or the accuracy of the model on a gicen dataset)\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "      #accuracy --> predictions for the given dataset X (the accuracy of this model on that dataset)\n",
    "    '''\n",
    "    a = p + y\n",
    "    mislabeled_indices = np.asarray(np.where(a == 1))\n",
    "    plt.rcParams['figure.figsize'] = (40.0, 40.0) # set default size of plots\n",
    "    num_images = len(mislabeled_indices[0])\n",
    "    for i in range(num_images):\n",
    "        index = mislabeled_indices[1][i]\n",
    "        \n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(X[:,index].reshape(64,64,3), interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Prediction: \" + classes[int(p[0,index])].decode(\"utf-8\") + \" \\n Class: \" + classes[y[0,index]].decode(\"utf-8\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "# Application  <a acnhor = \"anchor\" id = \"7\"> </a>\n",
    "\n",
    "<br>\n",
    "\n",
    "## Load Data <a acnhor = \"anchor\" id = \"7.1\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(data_directory, categories, size):\n",
    "    '''\n",
    "    Usage:\n",
    "      #create_data--> used to build our dataset from a bunch of images\n",
    "  \n",
    "    \n",
    "    Arguments:\n",
    "      #data_directory --> the directory of data \n",
    "      #categories --> the labels of the images you want to set\n",
    "      #size --> the size of the images after converting the images to numpy array \n",
    "\n",
    "    \n",
    "    Returns:\n",
    "      #X --> the design matrix \n",
    "      #y --> the label vector which every element inside it is a label to corresponding example in the desin matrix, X\n",
    "      \n",
    "    '''\n",
    "    data = []\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for category in categories:\n",
    "        \n",
    "        #get the path for every category\n",
    "        path = os.path.join(data_dir,category)\n",
    "        \n",
    "        #Get the class number which represents the labels of the image (e.g. 0  for Cat , 1 for Dog)\n",
    "        class_num = categories.index(category)\n",
    "        \n",
    "        #Loop over every img in the specified path \n",
    "        for img in os.listdir(path):\n",
    "            \n",
    "            try:\n",
    "                #Lood the image , img, from the specified file corresponding to that path with its same size\n",
    "                img_array = cv2.imread(os.path.join(path,img),1)\n",
    "                \n",
    "                #Change the size of the loaded image \n",
    "                new_img_array = cv2.resize(img_array, size)\n",
    "                \n",
    "                #append the image ( in the numpy form) with its label  to data list\n",
    "                data.append([new_img_array, class_num])\n",
    "                \n",
    "            except: \n",
    "                pass\n",
    "\n",
    "            \n",
    "        #shuffle the data list before construcring the desing matrix , X , and the label vector Y \n",
    "        random.shuffle(data)\n",
    "        \n",
    "        \n",
    "    #Getting the features and labels from data list \n",
    "    for feature, label in data:\n",
    "        X.append(feature)\n",
    "        Y.append(label)\n",
    "        \n",
    "    #Convert them into numpy array    \n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "        \n",
    "    return X,Y,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"E:\\DataSets\\PetImages\"\n",
    "\n",
    "categories = [\"Cat\", \"Dog\"]\n",
    "\n",
    "X, Y, data = create_data(data_dir, categories, size = (64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:8000]\n",
    "Y = Y[:8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 64, 64, 3)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explore the shape of X\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explore the shape of Y \n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e1b39d9730>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize one example\n",
    "plt.imshow(X[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e1a05241f0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO29eZClV3UneO7b91xerlWZtVepSltpKSSBAAmBsBowMjbgxsaBGSIUM+3uxmP3GHDHTNg97W563OO229NNNNNtozCLkVksWWPAokBghCRU2pdS7Vm578vb9zt/vFff+Z1TlVkJKr2U/e4voqLuy3vf991ve98593fO7xhrLTk4OPzjh2+rJ+Dg4NAeuIfdwaFD4B52B4cOgXvYHRw6BO5hd3DoELiH3cGhQ/CaHnZjzD3GmBPGmNPGmE9fqUk5ODhceZiflWc3xviJ6CQR3U1Ek0T0FBF9xFr7ypWbnoODw5VC4DV89xYiOm2tPUtEZIz5SyK6l4jWfdgjkaiNJ1NERGRJ/shUqzWeVCAo+vxgf5SrVa8dCobEuFCQv1eBcURElUrFawdhXCgk91WHeVRrNdEXCMDpMgbmJw2kWr2+bl+lyvMIhyOir1rhOQeCsC/1gyyOJSTPgTG8v3qtCuPkcTYavE39c2+gjS+DSkWe00aDjzMckcdicPuwQePzi3F+6Ks35EyMDzqhq2EbYlwNrnVDnasg3EuBAO+7Vpfb8MO+9AsQz5UxoosMXN9KGa6tOt94T2jg/iJwHivlstoZ3HN+eR4bjebx5DJrVCoW1CybeC0P+3YimoDPk0R060ZfiCdT9J5f+GUiIqqQPNlzC/Neu693SPQlwzzNs7PTXnvH9hExbmRw2GuPz8+Jvqmx8157YGjQa4+OjopxawuLXnt2YUH0pdNpr40nO5FIiHGrq6teuysRF31jM5Nee8/e/aJvdpyPbWCQ59ioVcS4qfPjXrtvdIfoi0SjXnt5fsZrbx+R56pYKnntWkP+IAXgxi/BDTc5NS3G5YtrXnv/vqtFn6/C26/6+PqF4/J8pOA8rhXlcUbiYa9tK/zDm68WxbiF6VmvXVY/8gODfC+le7u99kqmIMZ1xfnhrNXkg5kv8DkIGHnfBmJ8PJNwj+3buU2Mm13hc+VXP2o1eKlcddVVXntsbEyMM/Bj1dXVJfqKxTwRET305ftpPbwWn/1Svx4X+QTGmPuMMceMMcfKpeIlvuLg4NAOvBaf/c1E9HvW2p9rff4MEZG19t+v953+oWH7i7/6PxER0cTcrOjz1/nXrVZWZitxXwLeXD5lxhfWMl470pWS20dTDEzkMrzhiIjSSf5e36C0MMbGznntYpF/uPSv7KFDh7z2n/6Xz4m+X//4x732iVekx+MDk9AHc9yze6cYlwDzfzkn31AN+L2tlPkt95Uvf1mMe+sdb/Hah2+WBllpld9C3/3uI177rrffKcZZH1+XYl1ZB2CNpPv7vPbi6ooYl5tniy49tF30jU/ym/LkK8e99g23vVmMG+hliysakvMIhvl+WVhga6+qrJnHfvQDr71jh7SW9u476LVXl+ZF39wKW3GJCO9rxx55LP4yWwRdcD6IiM7DG7xU4PtqaWlJjBvcNkzrouXafOtrX6Kl+blLmvGv5c3+FBHtN8bsNsaEiOifEtFDr2F7Dg4OryN+Zp/dWlszxvxzIvoOEfmJ6M+stS9fsZk5ODhcUbyWBTqy1v4tEf3tFZqLg4PD64if2Wf/WZDs7rVH3vouIiK69pprRN8M+G6zi3IVfAR857V8zmun1Eq3P8g+U7kiFwPnYCV5ZHSX1+5Svv3Jc6e8dn9Pr+gz4P/1dPPKbqMo/f5cPs/jYknRt1rgvt0H9oq+pUU+B3WgalJqtf+px37stQ/fJv3tCPj9T/z4ca/94fffK/dV4nmsqlXwBKz6IrOwtCqvSzDAayaxZFr0Pf8UzzHexedq+055zGm4hnPKRw3C2kR/ks99piQp0alpZidSSXlPmEDMa/fEeb7j43LNqL+P52gUv+ZP8DUM1CQdFgvxHG2Et1/IZsS43Brft9mC7AsCpesDdsIoqjNf5uNO9sjzHWqt1Tz0wP20OD97xX12BweHf0BwD7uDQ4egrWZ8d9+AveN9v0RERAEVAXTmxEmvfdvb3ir6KnmmlxaW2dRLxGNiXKnCpm+xJCmpVIzH+vxsbpXL0oTthsCZsJrjapldg1KBt59bWhbjdu3ezd9Zk1TT6CgEt+jIuBKbiPkyuwba1QhAXMeZuRnR1wNBHvt28TyeeOonclw304WpfknpnDz+Euybx/X3SremBmZmvFvSST0JDlLJrLDZav1hMa5R520UVUDMiZOnvfbhg2z+F6QVT6fOvIobFH37D17vtbuiQLkqejfdy+d4bW1N9Bk4p0/+4Huib2iYKbbePr53qirwh+DQqjUZmJNMspsQTnE7KofRWjbrtXsGB0Tf1Jmm+/nw179EiwtXnnpzcHD4BwT3sDs4dAjcw+7g0CFoq88+tH3Ufux/+U0iIpqZlr7mygr7toGozKDqS4F/2dvjtcuK8pqbZTqlohIWFiemvPaB66/z2nGVeXZ6nEM0e5PSVzbEPjyGVJYqcn3g1CkOq736Wkkx/tVXH/DaP/++94i+vh4+tiJkrM1OynP1F1/471779/7dH4m+sJ+/d+y5S/veRESxGPvUi8uSCjp0YJ/Xxgy7YlYep8/P/vHM8qro272LQ3xrJR5X98v3yxf/7M+99gF1rvbs5DWHdA/7ssotp1VYM0n2SKqTgEa0JT4Wn8pGXM7zORjslueqUODv6aSnNFB9yzBudm5MjHvrbW/z2itrWdF3+hTTvYEE349nXz0pxiXjTD9Gk3KNpFxonv9vff0rr0u4rIODwz8guIfdwaFD0FYzvrdvwL7z/R8iIqIjR46IvrNnznrt89NTom84zSbL5CybtNddc60YZxtsup89d0b0RSFbLgpuQTGbE+PS4CZUlHhFucQmMuaz162kjMIRNvVWV2TU2e233ea1v/ylr4i+e+65x2svglvjq8lrVPbxcVaVvkEcvBIfRBTW6/JY4iEwb30qezDDJvm2bZyXncsrOsnwcad6pFm5CFmN8xAd2a8yt/ohuq6qjM8gZKZVy3ydiuqWHYN7JxmTZvbwTna3UAcgD1GOREQju3d57T4wl4mIAhE21fX3gg0+rxWgFdfWZIReucDnqlxVfgg8g9kCH6dPjYuDixLvHhR9i3NNnYTvvE5Zbw4ODv+A4B52B4cOQXsj6NJ99o6fex8REe3auUv0nTjFptjVh68XfTlIkEDRiIZK2sMEmt0H9og+TITpgoil4WFpVi7OsskZCkvztlrnc9Xf3++1F0BqiohoESKwduyWiR9liJITmnYkXY1qhccND8ikhxeef9Zr33DzLaLv8cc5AcUP0l+3v1VGJdYgcjAQlmbr6hK7SmfOrS+j1ZNi8/bceXkOtm/j5CU0fQtlaZrOTo157UMHD4q+5QyfAz+EoJ2bkSZybxe7Xl090owv1/h9FoXkoorSsTN+vhYhn3wmcmBOnzolV8jTSXZDwmE248sVyRThtY2nJGNQhtV5X4LHYZINEdEauIShqLxmJ0803danvv//UWZlyZnxDg6dDPewOzh0CNzD7uDQIXhNSjU/LWKxOB2+qeljzs9JqWf0nRcWpKhfdw/7RSXwQ6/fu0+Om2J/LV+SnFQY9MpRkx1pISKiOGTSJZTs8dQMzxnlf7dtk+KCcRC2CJH0UcNAeYVj0icLRtnnW1pkCiYWk9l9vSCJXFdiCrfd8iav/cxzL3jtmblFMc4P4sCrOXktYnBXRJPsD2dyknrLQRaWLyqz2b7xNyxHeNN1vAaTHpASy9t3HfDaR3/4hOg7BAIne/aw5HdFac8Ppnn9ZHzstOhLD3KW4V9+4QteO1OU0YAf/PAve+2iOqdnx3k9Qkci7t7L1B7eE3klXoFU7VpGRtCdeIGv09U33+i1J86OiXGjI5deByEi6mlFX/r96z/S7s3u4NAhcA+7g0OHoK3UW//QsP2FjzZ140dVNZdZSGLRGmBR0Id/dYwpuj3bpb73LFB0I6OSUstk2KzCJIgd26UJPg/UW68Sayjkma6qQoJIOCJNp7klqAijzD4s/5RR5lx/P1NsaCJnitIkfO47f8Pba8jIuIPXcpLPwRvf5bXLVpp98TC7PHWlof7SS8e8dk+c5zRytaQRs5Bc9MxxKSz8piMcKZgCd2VpTR5LCLTnYyrJhCwk68D9katIwZE4lHjq7ZHnOweCJiVi87wnLPeVAXotYSRtZgJ8ftI9MnJtHuheX4BdmZnpCTEOyzql4t2iL5cDXcUucB2Dco7FIif8NNXbYY6te/rBv/hvtDA77ag3B4dOhnvYHRw6BO5hd3DoELTVZ+/p67d3vvcDREQ0PCR96jmg4jAUlYjIAqUxsIMpmKqigurgqSwuSqqpBDXdsBpmQfnNw8O8lnBRrS2orLq8zP5Toyp9vB27911yHBGRP4AUoKSrinmey959LNzwhT/9YzFudzf7f/GopAdXgPI5Ocf+5P/8v/0bMa60xsc2NS3px2Qf+721AoSY+mR2XzrOYZ8FlVW3tsp+6CiEzur6fKvz7ItPz8ow2J0QntsAP12Pw8y8REyun6AmvgWxk0hE0nd//UUWBGkosdJgiKnPW3/+l0VfAuoCrGT4mMPqNYqikkm1joP3Zh1ETYt1OcdymdeCzp+XmaHbW2tg3/n6X9Dyz6obb4z5M2PMvDHmJfhbrzHmEWPMqdb/PRttw8HBYeuxGTP+C0R0j/rbp4noqLV2PxEdbX12cHB4A+OyEXTW2h8aY3apP99LRHe22vcT0aNE9KnLbSsajdL11zejojKr0lTqhrK7paKMYGqAGf/ss8957euVeMWxn7A2+o5dcsp94BpMz3BW134VhVe1bAEdUFlYBdCKD4TYBI9EpWn6xJOPee23vOV20Yfuil/psYWjTCH93Xf/zmsnfZJqSg+wK5PNSReiAJrk28Ac/9y//S0x7lf+xb/22vWgNM9zGT7OZDebn6PDknp76Ktf9dpnZqdF3/vv/SWvHQ7xcY3PSpeBGmyqDu/YJbpWVtmk3TnK16+kqLez42zS7hmR7uFKATLnQJTjga99QYzbu4ezJPt6dou+lRk+tlSvpM0aMJXBAZ5jV0q6V2WoAzCv3MMizMtAZGNACXGgy/2W22W244Wq5uFgkNbDz7pAN2itnWlNYIaIBi4z3sHBYYvxuq/GG2PuM8YcM8YcK+Rzl/+Cg4PD64JNrca3zPiHrbXXtj6fIKI7rbUzxphhInrUWnvV5bbTPzRs7/3VjxMRUVCVVgqByTIzJVcasZrq7Cprsw2npajDBKzSRiMyyWQFykaN7GCZ4+yyLM8UT7GZtrYq5ZGHIFkHI/76euX6ZAlkoFGEgoioF+SiqxUpoFDGsRBZdvLo34hxERCbKJalCV6q8ep5OMwmnVE/65MLzFbc9cGPiz7U/MuVmCFYW5Euw7ZhNluX1bkKgW5bvcBiHsG4lOd++cVXvPZb3yJ1CZdB6OL86ROXbBMRvfltd3ntdEKKOizMchLLt7/JstVdUXnvxKDEU68ywQmuy+EPflR05edAAh3u6dWijFjshuQoLd3dFeHr1A9JPXX1jExMsIaeFq8othJ7vvXV+2npCldxfYiIPtZqf4yIHvwZt+Pg4NAmbIZ6+woRPU5EVxljJo0xnyCizxLR3caYU0R0d+uzg4PDGxibWY3/yDpd77zCc3FwcHgd0WbByX771nt+gYiIdu+RGWtTE0yHxROKtgCqZQR0wEN16fMuQWnnuoqCQh/HB+IVfmXcYMadPyT9okUQusCIqMyqLPFbhfpEuoRUTzevTQQism9sjLXus+Dnrj73YzGuUmV/XkuQ5yFKLAiCmXWr6hzXeFwjIs/33b/IPrwPtOFLVXmuXgbhy5Q6zr0HDvGcVnm9ZGFF+vZ79jGdd81BSYM+//Jxrx0w7L8GVXhaGUInSyuSAvz2l7/otSMBXsdpKNozDoL7IeXxxmDt48A9HxB9AaBqs5C9tmu/FOfMwz0ST8gIunMnueR0BKLrsnl5D0cwu69Xrjl0tYRW/tt/+gOanhhzWW8ODp0M97A7OHQI2qpBV280KFdoUhIrqzIBpQLJACFVxbW/j03E82fY5Ln2Bqkvv3CehS3efKOMMPrhE2wKX3cdCzycPXdOjNsLiTbHXn1V9PWDHtv4OIsTdHdJEzYK+uG5ooz2iqTYnF6ZkRRjuotdg4UV7ksqLTyMmuvqllFWcShRNTEHWu5G2vt+KPkUV2WuXj32qNe+4e3v9doVIymjN7+bKa/Mgko8ArchnmbqtGyk21gCrcCXX5YCGPE4m7R/9Vdc/fb2t9wmxkX9bLV+72tfFX2oDx8J8rstEpJRj31AjTXU+aiCBjwm3RAR9UKpr1lw8yo5Sb1Nj3F14HBKRuHFwQVKQDmsHdtHxbhREFp57PHHRd9iS0SjrKhehHuzOzh0CNzD7uDQIXAPu4NDh6CtPns8HqNbbmn60mfPnhV9+/Yx7XLynOxLJKCMcoPpsPFzshxyKMg+3rlx6Q9HY+wXzS1wiGPDypDEIqwdDPXL/B6kWfbuZcronCoPvXsXZ011KXFBA6KHO6+TWWTPP/MkzxeowkJV+v1hCAVuNKQPXAS6JgSZeZmc0jEPsC+bTgyJvpPPPuO1EyC6Ge+TIqGlWTj/IXkr+cO8zvC33+EMvr37JL3Wey1rw9dqMhx3ZZJptA99gLPoVpbktf3WlzkMNh6W6z0+CB/G2noDSiBlL/jDM0ty/aFc4HdiNiNp1pVJDpsen+b59ilxlkQfU2WjoztFnx8u4QwIWM5Nz4hxP3j0Ua8dCMnsth07m9tEMVUN92Z3cOgQuIfdwaFD0FYz3loukXMNlPYhIjr+CmcyXX/4RtE3PcEU0iBoq/confH0INMpibA0cyIpNu+ifjZv+7uVzjhEQdXLksaIxSEzD7TTBvqlvjxiclmahFGgpMbnpRsSBj2zLAhspMKy/FMOTHej0tmuOcAuRDbL+351TNJJeSh9PbUko85SkPX1g4e/yXOPyYjCOFCM2/ceEn0WIhFHwJPZPyjN7LMvsOsSiUhNPr+Pr+GTx5/22qdfeVqOA133bEVSXjVwV+Kg75+KyPtjdoGvRUqV20K6MF+QrgZmIO4F7cFqTbpXL73CJZ4W5qR5nkyySxEEejChSjtf3X01f1C1FS6Ug9ooIta92R0cOgTuYXdw6BC01YwvlUp04mTTXH/TkTeJPtR3++EPfiD6tsPK5gqshqZUAv+pE+wKjAzK1dbFNU7AiCfZrsT9EhGNgkDFmNJV606xyY8S0UP9coV5bY3nODQiy0stnueIvZtvfbPoe/ToUa8tOQKJSplNcq1jVyjxvqNgtu4Zlufj9BRr4c3lZTRjbp5Xu6OwuutTFmKjwvNYm5LVU6M+3nfVxybnj45+S4xDzbR6XUb5zWT5WAoFdjt8DZkAVYPtR1VkXNLP229UOLpwoEe6XqdAG29Iab+dOsvXrD8gXY3zk+xi9oO0drYkZc6vuY71DA/s3iP6KjU+V7PzfM81VDrLzCSLV8Ti8t6/IL8eDLgqrg4OHQ/3sDs4dAjcw+7g0CFoq89ORET1puM3Dr4OEVFfL/tJYVXCZ/dOjjgaBw3vXF5GhR08xJqXjaJUsh1JgsgkCCgMD8oSvOfOsN9/+JDUpR8fZ59p+yBHna0p0cpeEMJcUtlgARBcfOxHUpQiAqIdKzn2V8/OzolxKJyxsib97VqV1xX2pJnmQiFDIqJTIOrps5JiNOBv90KGVlytkQSB/olGJV1FxA6+HzTTfUE5LhFnn/oCfXQBdciIC0HEWKUofXtfnfdVVgKc27fx9TWW323nZyT9VQXRj4UVec2CkH02rrIk0yDOmYDMubiVIqQYsXf2nCznvAAluyJw3tYK8nzsGN3ltWfU/Av5JhVcqcjjR7g3u4NDh8A97A4OHYK2mvGhYICGtzWTS6IJGUkV6WYqxK7Iyqeo0X7V/gNee+KMTJjJQBmdq3ZKjbuXz7B4wFAfm15nzp8X44aG2DzHUk1ERN0gLLAEOvT7RqSgwRi4Gukh2Tc7yebzgEq0WVzmKK4EmPTlkKR76iWoTKoitRKQeDNXZvPwyWceE+O6wCxOqu3XYJthoHKMoryiETbr61UVbQjRdqkom7QrWUl1WtDTSypXYDtEJi4D5WoC8ph9QL0V1fnIQ2GSYdBta5Slm1cusvn70ulTch433+q1dw/L61mDqrw1SLrJFeVxImU8MiBdx21JdmFjEJFnVLXamXm+HxMqerTeem37/C4RxsGh4+EedgeHDoF72B0cOgRt9dnD4Sjt29/M3JmalAIEY5PsO2/fLv2igmVf6MQJ1hIf6pV00tgU03nJoDy0TIb9Vx9knhXKMotpKMDbjPbIzKgTIEB54Cqm+Z49JUNF940wVfPqyZOibxSomoISB+yCmnFLZ5j+WSxJOmV/nI/tIx/8edG3DGHBD3z3u7xtIwNwkTbzqzK/8QiPrVQ47DMrXXaqgn+YCMj3xjRk+41s4xDkiqJEU2leY6hW5XGW8/w5ZHiNx0RViWkQHPEpMY8aiEcWgMoLBGQW4LYe9qMDQUml5paZ3nzlpPTnewf5Xt02xNd2sE+uxwTBLy+uypLN1SKf2KkzvP3uPunb9wIFqKk3n795T2xUBmIz5Z9GjTHfN8YcN8a8bIz5ZOvvvcaYR4wxp1r/91xuWw4ODluHzZjxNSL6bWvtISK6jYh+wxhzNRF9moiOWmv3E9HR1mcHB4c3KDZT622GiGZa7awx5jgRbSeie4noztaw+4noUSL61EbbKpUK9OrxZhL/zlGpiT0zxeZiPiupt1CQqaESlA32q5K2vaCXlsnK6Lodo0zFTY4zZbdvnyzTMwf0RkWV3+lKcfQblqQaVFF4KICxX5UBWgb3pUvRJ6kUf965g+c7d/K4GFcKs602AVF9RETHzrIZuJJj89M0VNSZYdMxpHLsljM8/zTQjSGVhlUDs3ulIu3H5Sxvo1EDjf2IPOZchs9xTem1l4Hq64eySNMrUvQD9fqyDemWZUGkIwZU4V03yYxDLDn91Kl50fe+u1k7/6qdMsNxGTIQiwW+50xVZr3NnGM6NqHqIiRAHzEB9+nEtKTe8Jqtrcg57mpl0vl9l6z81Pz+uj2XQKtO+41E9CQRDbZ+CC78IAys/00HB4etxqYfdmNMgoi+TkS/aa3NXG48fO8+Y8wxY8yxUrF4+S84ODi8LtjUw26MCVLzQf+StfYbrT/PGWOGW/3DRDR/qe9aaz9vrT1irT0SUYkUDg4O7cNlfXbTrGH8P4jouLX2j6DrISL6GBF9tvX/g5fbVr1ep7XVpj+e65VCjwP97Peursqyvl3DvNA/DOGnuvxvqo+3eXCv1GR/+hkW/AtD5tU5pVE/CAomS8pn7xviOWYy7A8vKJ3xt9/C4ZXHz8pw3DRky9Xq0tKZngb/Etiwhk/62xNT7MsVSzIzagJDdUHNpKiUUzA7LKB89mEIXUY/eikrM+xCIDiZyUhKDTXaI0A3lmvyWJKQ9TavxCKLdd731CrSYfK2jUOIqV8JMZaAWq01eHsvHJfrID1dvJaQiMiX0izo109OyWs9sI3XnkJBXrfo7pP08TDUrVual7RZZo63mYPMv65uVXMAhFJ37pb3d7G1PtNQIc2IzfDstxPRrxHRi8aY51p/+11qPuQPGGM+QUTjRPShTWzLwcFhi7CZ1fgfEdF6S3zvvLLTcXBweL3Q1gg6Y4iCrci2pSUZRRSJsunYpSLjJiaYuukbZjM4rvS9p0Bf3qiSSUuLvL/9QLfVF6VZhpF2aRCh0HNGcUSt1T0NZYDm5+RSRu8BNr+WVVbd6E6Oypsd58g7xSZRvcam3tKCNM+v28O68WPTTPNllAZ+GqgsnW3WE+OMOyEoEZa02YkJdlEifhmFV4bsM4yM60lILfRMgV0DLdaQhc8hEJK06tXTZdnsjgRUNCCUgzINviemFyW9mwWqLFuT904XZEnecO1Nom8VMhBTKSjVvSS3n8nx9pNxmWWIIqcEAp+LS5JiRLq3pERCd+9rUm9hJbiJcLHxDg4dAvewOzh0CNpqxgcCQepPD12yrwDRR7MqaR8rvE7PsYk8nJaRa40qrPRWZDTW4ChXID13ms3PniG54lkEDa9SVW4jCKv4ayu8onrjjbJc1ewMux3X3XiV6Dv24ye475AsmXTiRWYMDCRqRIw0wROp9ctNzS3xqvUyMAYD3dI1qoJvMDMrXap8nIUWelM8zhbkufL5waxU0W9+w+ZkHRKP5lal21SvsU2+siZdEhTRqDeAqQA3g4ioN8EuSVWJaExleH89UL6rkpfVWBtVNq33jMjozliQ3QTbkMe5Ms9u2tI0n6s92+R9bgK8jYUVtRoPAiqLK3z9tm2TK/o50M4fGpIxbJPjzW1UKtIFQbg3u4NDh8A97A4OHQL3sDs4dAja6rP7jM/LUMpmZcQV1k4bVRlxEEhFts7RXlYJFWAZ6JyiLXD7PWnOMlpdk/7q1buZljs3ITPKliGKKwaldR/+xpfFuEad/aZzp2SkVhwy3Z578qjoCwbZF42CgMSA+kmu1tkvDQZkBlUV1yqAhgr5pOBDHnTSk3FJMf6zP/hVr33Tbih5HJC0zgd/+U+89vSSpIIsRHJlIDOsJyhpp7UGH0u5Lv1hH4R3IL15QFGiN7+Jt7lUPyD6pr/NdQMtrMckwvK81WCO+by8J4qQ01FQQpLDQJv5iLexqAQqyoavxWpO3vvdIb7uIzv43i8XJecaj/O4pWVJ7fUkm+sWOhMU4d7sDg4dAvewOzh0CNpqxlerVZpulR3SpWXPj7HJXK7LYP4dw1z2eO/+XV57eUlqhU1DcsNt1x8WfYtZ7htMM1VTqki65/lXnvHaLzzzlOhbnmdKsFRk89OvIuhQ46GhqJpqCUw4pQvnN2wKlyGSKpaWil/9IKKxqtwhgyWZfKglp+ZY5+1Hu+U8cis8j/puvk65msxs/uT/9fte+z99g6EAACAASURBVD//7v8t+pYh2rAM2m/+qIzCa1TZLParqOxogqnOoWE21f/lb79XjJud5ZJde9N3ib5zz7A+YLqHt1dYk8eyCvdcqSZdnoVppsb27pfiFePTHLUZ8oEgSFjSg3iL7BkcEX0rYJIvQrumSlgPD/C56+uV2whHm+fH70o2Ozg4uIfdwaFD4B52B4cOQVt99nqjQfkWddGVkuIVd9xxh9cuqIw1AyV5T4IO++5R6bdkV3nc/LzMKOtK8v7OT3E46+y0FK/4yY+5Jpqx0nerVUCf3LJ/Zq38zTRAf/iUmAJoBlKtIbdfBxoqlmS/vKBCQMt1po38PrlvpKgGoLbZQI8MsV1a5jDPfEGGsH7xD5lKnP25G7x2ciQlxo2f5vN40boFUG9lyLibzUjBkbUi+842INcOSobPtwE9/8ePnRDjjv0IhEkC8rpXQSBkYhbrxclbH0Nz15RIh2/sjNdevPYa0bdv10GvHY/yNucX5DwWl/i4ZzLy/o5E+HoORPma6WxKpAB1eet0q+ZAXfn5CPdmd3DoELiH3cGhQ9BeM75Wo5XlpjnT0y8z1ipgqteU2eqv8ecSZCvVKn1iXDTBmUWrGWmKrQHl9cLTHFU1C4IXREQl0Grz+6RZadFCAtO9YSVVaEFnzSgzHkdqvTQfUHFYyrjql+djDnTTu5SgxBIIPmwPMmVXLEiKEaOxBlIym80GeV4/eoxN5vOz0jStEV+zRkXRZiAuWoWIwqwq/+SHKL+yEq9IELsNa4ts7j/y7RfFuOEUH6dRtNlqju+XZbi2gYZ8zw31sJuA+uxERBlwNaolaSZPnmc3EE3oVEpl5oEbtaaEJ1JBjkxcA+GMkoq0276N3VakM4mIKi0XU5v+CPdmd3DoELiH3cGhQ9Bm8Qo/pbuaGmTlvIxgysDq+RSIPxAR3XP33V67CtaiXpHEyLWSWtE/9sT3vfYSrMZX9OolWEG6HBGtI9OrTXWxOWVWYaJCQ5VkwpV1H7SryjQNQzJJyMjt7+5jc7FU4e1nVTmsJAg+RLtUhVfLZmUVWJN6TR7/GpiZOb9iLoBZqEACSlTVDgjA+aipJI4qCDH0gE7etm7JLOB1mlmUCSgFcLHqMC6kE4hwnLqeddDJy6jSUzfeepvXxvsgn5P3ZgWEVS6qVgsJXaEIn/uiut9Qi1Hfc15pMmfGOzg4uIfdwaFD4B52B4cOQVt99lAoRKO7myVp68ofLoaZgonGZWbRWvbSmVGjA8Ni3Pk5FvKbnZ8SfYvQVwe/Rs8D/fKNaAxZN0P6VsLfVhl8BrZplE8Wh3JNERDH0FFyqKG+pmjKCEQKBixmckkhhFWgMItlqbXegG3W4BaJh6W+fI74uuxVAohTy+w7RyK8xtCtylQHYPsBFdWGxznQxfSa0hKl1TzPV0eQdUF0Wm+A59FQ77lylX3shpXbqMPn5eVp0Td+iqnJIujX16pS5CIU4n1rnz0INGgesvH8QXldQn6e88AuGT1aa5Xf8vnWf39f9s1ujIkYY35ijHneGPOyMeb3W3/vNcY8Yow51fq/53LbcnBw2DpsxowvE9Fd1trDRHQDEd1jjLmNiD5NREettfuJ6Gjrs4ODwxsUm6n1ZonoAscSbP2zRHQvEd3Z+vv9RPQoEX1qo235/X7qaVWmPHpU6q/19rBh4FPmXHCNkwiWQFvOp8r05EAf7Iknvif6ahUwTSE67aKql/BZm0QNoEiwS1v7uM2gOsORAJv/IaWDhqWLEkBRZRVNWQVaMZ2UCUUW3BIU5vAHJa0VApPWKn383jiPDcW5XFMmK83P/Tt3eu262kYhCnpvSTZT33bdDWLczCq7E8dPnxZ96CjlgebTdCmWiVotSPM5AgkusTAfV4+KPCwCzafviWCA3RfbUBGRcCOk0xyFN372lBi3Csc5snuX3AZEXGLl1oa6sbqgZNeZM1IfMdJ6ZrTgBWKz9dn9rQqu80T0iLX2SSIatNbOEBG1/h/YaBsODg5bi0097NbaurX2BiIaIaJbjDHXbnYHxpj7jDHHjDHHCioIxsHBoX34qag3a+0qNc31e4hozhgzTETU+n9+ne983lp7xFp7JBaPX2qIg4NDG3BZn90Y009EVWvtqjEmSkTvIqL/QEQPEdHHiOizrf8fvNy2qtUqzU61ssz80ve59bZbvDaGBRIREWbEAZ2U7JX1tJ749gNeu7wmfTcL32ts4NegT1a/iHnjPh9kvdVJ1YTDQ1M0USzOdFI8LKmVLihnXIXwymhQ6rX7LM5Dbj8Y4HmFsb7YsgwjJcjeCiqKJxZjjyyzwKGi1ZC8XVDwU69vLIKPWgdq8lvHnhDjUjDH5Yysv0aG9+eH2nRVUuG9QNHVS/K6FyHTrSfCYbZBFbabgnMQLMoMwTBcp3hCZggmgErM5XldoadbCn285c23eu2pKUkLn4H6BBXQzh8ektQy1pkbHZS1+y5cw6BeJAJshmcfJqL7jTF+aloCD1hrHzbGPE5EDxhjPkFE40T0oU1sy8HBYYuwmdX4F4joxkv8fYmI3vl6TMrBweHKo+0adKstM+vGa+QaH5ZpfvFFKU5wYC9H1MViTIOMTUgtspMn+XNdlRLCaDhkNHw+JSABdnFDlZcKhHhsDCzfgF+a2WmgEZNRWe4II7x0pBZm8SWRUtPiGBgBqFwSzBRLxCCiKy6pppLhcTklkvDyDGqhs8ncH5AmbFeEt+8PK1cDzPrZVdZC398lSzdhlFxtSWrh7ejn/eXzoCW3LMdhRFpY+V7bB8AlAZM+NyfLggfARcN7jIioAmWlq9ovgzTJFOoGNiQt/PDDD3vtq66SZbx3QMkngsy/YEC6V+NjY157XmX3pbqa+9bReQgXG+/g0CFwD7uDQ4egrWZ8rVqhhelmQopRCSJBTHDZIau49g5x0H80xyvAf/3AF+UOqhtED4FZWRcmvVrOrvM8+tPSnAvBMjvOtysho9hQoKJekYkqDTjuinI1irCSjJWhanXpaoT8fNnyZZXgAlGE5VWOPNSRVd0xpkGrqi8cZfMxsL4uB5XBZYirOykZgQSXXtYKnF6QJbsqkHRz1c7dos/W+diyGE9nlTagYdO1qpiFXAOZHD7fdaUzh2WTGiTviUgMWBJ1LZAdyi1DspW6v2+/k6XStQn+4imOtsPkqKsOSnN/cJDZJ73qPrnQjCytryOwQuTe7A4OHQP3sDs4dAjcw+7g0CFoq89ufD5PcDAcklTNEmiSR7pkWG0uyz7O049zeabFZUmfCBpK/YwZoNTwoMNK5DAIAgF+5bvhRyzZo6krXAdIJZTfD8cdMPIcEIgI4hpDWWm+h7t4m76APNAcRKFVIeMLSzAREa2gCKS6FjXIqquAD7xckMfpA384EpMRXViqKFNi37ui6EwDvue8ivKLhfjaLIFgZlEJjkTgGkZUVGKlxvOoQEYcXj8iouHRHV77zDlZS2C4n89P/4Csd9ADlGbUQmZlTD5apSJHIu7bIYUn0v0c2dcHdGZmVa5vRHuZikzF5DOS7m7O49GwpHoR7s3u4NAhcA+7g0OHoK1mfDQapWuvaVbBfOyxH4q+WIzpK19FRh/NzXLiwMQ4l9vRIgNokVtdPRVM62jYQFuafSICSem6h31sIqF2nSVFayWZqtEJIqhPXlIlfNDArYK5a2LS5JwEAQ+/YlqwnFIFTPeIMu9Qrz2oot9CDb4tZsF0D/nkfJE5VIGIlAA6sgDXM+SXCSiGMPFImufZMn9vaY3N4Jo63+kIn2+jzncZXLsCRNdVyjLSbOGl41471i2lGfp3sEhHQlUfns2we7F/cJvXXivLexhrBFx0LWAbMwW+trfcdLMYd36c3Yvxealf39NKltJVgxHuze7g0CFwD7uDQ4fAPewODh2C9lJvZLxQ0nhCUgfXXHO91z53Xor1vfDC8167sYGuO7orVrkuWB7ZEvu1xYrcRjTEfV0qUwyB4ac1v/ITYV4+FRJbhjWBnCpRHAXapQbbKFd0Bh+G3Mr5Ix2G4oWrEDpLJM+P9nN7gNYJQziuT1GRPqDNCiVJD67lUOwSBTvk+gNB2GpVZYqhSGMkzPvyqSxD9OAzq7IccgV8ZSvKgis9f9C27wffm4ho+9B2r53ulpl/DZh/eoDpx9yczMwLwP2XU2Wro0CfJrp5G/PzUvwpu8bnw6cERMuteoBapBLh3uwODh0C97A7OHQI2ixeUadstmlm7QQ6g0hGbT3/0gui7/D1bOL/8LtcfsdnpCnjM5jNpmg5oHjSEN0UVjRIEbPSVKlkP2SblYF6qynNMh+YrVrjvAamcFzRODmgYPIFNp+NTx4nZlTpcxAA03oZTHefihREQYyMcicsuEpJMLsb6tVQKPI1i8RUKWbIDkukWLCirlwSv5/dptVVafquQdnjYAh2XpU+WpmYEtQuD579IOgeBvzy1o9E+TiDqpxXby/Pv7dbXTMQHJle4QjAdFqa+wug11dV0YzXHzzktY+9/IrXzjak67V9kCnBhnIdL+ig6BJaCPdmd3DoELiH3cGhQ9BWM75ardJMS2tuYEBGKc2e56SWZFLqlM2C9G6+AFUu9W8VmN3JqFyxjcJqawAi0jKqcAWuZlZUhF4syqvzaC7qk+jHxJKSFJcoQlJLfllKJ6NLgZFwVVVaKYlaZ2r+NTgHBkx85dVQIAACG7qcEsw5BFF+JqBEI/Bc1VUlWDDjlxY52ksHeKFrVFTnKhTBc8DHVa/JFWc0XY1ObMI5gXnuD8n5huEqZpfnRF8I7p1SUZ5vrEI7B8eZUO5hXw+b9TXlHi5nmEEY7mf56Gxe3h9d3RwpePr0mJxjvJkc5cQrHBwc3MPu4NApcA+7g0OHoK0+O1mOgIuq8jsrGY4WGt0hBQJefOIn/KGOZZEU9QaRSF1xFWUFfQGgrhKqtFIGBCI1LbeYYSokCpSRX/mJKBRxUUlo8FnjcSlskYDyT/OQ1aQz5y7Ql0RS8JCIyIBT7N9AXx71H4xypP3gmxs4zkJF+tRYoiqiIgWrFZgXbD4U0oIdEBGpyiFHIZLPWojIU6l+VfCBfYqmxPOP10lHX2ZzLGwRMvJcnTvB9Qjeccedoq9c42sT6ebrqcVCfDBl7bP7fCns5HmoczU+wWtXqS5JAWZbNOhFAqq4n3V7FFplm581xjzc+txrjHnEGHOq9X/P5bbh4OCwdfhpzPhPEtFx+PxpIjpqrd1PREdbnx0cHN6g2JQZb4wZIaL3EtEfENFvtf58LxHd2WrfT81Szp/aaDv1eoNymSZ1kc3I6CA0bQJZWYlzLcsmbQjM7lpDmUNA42SUMARG0Fkw/1E8gYioBxJ0FldkwoLfgPY8fK2hzHikPxrq97RUZjMtEpX0TwYi6FIggFFRUWF5cDUCqhpRA8x6NN21q1EDc1GXwEIxjgJYhbocFn5PUz5Y2dbn4+PMq4SZaIhp0Lgq6V1CKg7M023DMlHlPFCzjYY6IZjwA9Vf67X1S2r5SvKaPfOj73nto9/5W9F38JrDXvuXPvIrXnsVNPOIiA4d4ii5qXlJ7c1DOaso3MOJmKwEW4Sqtrm83H6uVR7rIrcRsNk3+x8T0e8QiTjCQWvtDBFR6/+BS33RwcHhjYHLPuzGmPcR0by19umfZQfGmPuMMceMMceqqjqKg4ND+7AZM/52Inq/MeY9RBQhopQx5otENGeMGbbWzhhjholo/lJfttZ+nog+T0SU6u5df6nQwcHhdcVm6rN/hog+Q0RkjLmTiP6Vtfajxpg/JKKPEdFnW/8/eLlt+XyGwqFwqy2NigKEkVZr0gIIQcExoQGpSrvFQPyhUJZ+P9bGiifYTywU5LgKiCNWdJ02rSPfwlBfn/i8Av5aVfmGDfCjc1kptJBIcDgulm+uqhp2dZiHX6054BrERZluAAwx1bRcDwgooP57xUp/G/1D7SuioGVtIz8S7oOsOh9DaT6ve/bu9dovHn9FjMMzoK8Q0oo9UEp7YUEKNiLNVVGCp6slnle5IOnHZ5/nOgYTp1kM9Tf/998V4xYX2S/vicq1iSSUiK5AWPDktHx/luF+3H9gr+ibmmyKUfp96xvrryWo5rNEdLcx5hQR3d367ODg8AbFTxVUY619lJqr7mStXSKid175KTk4OLweaG8EnSGiQNPQ6uuXUXJ1mElYlaP1g4653w8mZ1SasKUqm1hBZdAFgCbKFthMayhFhnKN+3Q0VhhKIUXAtagpMzuTB9O3oSPX2KSNK8EHP5So6u9nE3ZmXoo6+ESZK2WcYdQc6KwZLewONFpVRV1l8my2opvjV0IZYcgGK1eViQ+sqPHD9tU0SlCeKaT068+DBtsc0JIRdX8kk+z+rK5JSgoPbXmFz6Nflc1C013TlLaMUXjSJfHVeGy1yuftj/7g34tx/+vvchhKVVGpy1A+LA30Y78qg5atsPt57pTUaTxy801ERBSNKo0/nOu6PQ4ODv+o4B52B4cOQVvN+Ia1XjmegKqiiSvCe/fuEX2Tp1/y2pUiaL/VVHkmFH9Q5nMEtNRykKSgo7awIqs25+RnNueCQRkJNzjILsq0ipbCAC8t1tDfxaY7JtoE1GK2BRO8rJIqgpDEgqWmNHOBEWNGlcBC0x1Xy5VqNUUgUaW4JI/FgLnbqK1fkgjlnRsXHQuWa2ITOVeQ76gwRkdqdwXnBBGQNVUJFvv0dUfmolSRJzJg+NzVLYh+FKRLEgSXsDueFH1nFli4JQjMxf5du8W4xgqfAy0ZPTY+TkQXMwkI92Z3cOgQuIfdwaFD4B52B4cOQVt9dp/PUCzW9GX+/nvfE32hKPvb8zPSz0Utd5+u6wTAEsjBkIoeA136IERV6SwpLAuktecNKBDEohz1lCtJEULMSisXlY45zD+qBDZqED21WGadcaN+kisloNSUfngNxBix5NVFAhVYKrks59iAsahRr/XrMSpMr33klRDmevNAz1NH8iGjiS4q6r8TEVkQj2yoqEf0v1EkVEdwYhZjRPnsXUCRFpXgpDF8zeJhjjwMhKUwid9CGSp1PQ/u2u+15+a5LsL45IScR3cvz7FfirKWL2QTupLNDg4O7mF3cOgQtNWMDwQC1NvbNEXOnxoTfd29kKivTNORHWzmTJ076bWrJSkugYkkOlILq2iGQPcsX5GJMOEonxLUKiciimHCArgMUUUjJkF4Il9QwhNF/p42W3HOG4kQINVXUdpvSBMhvaS1yWobaJUFfJemGKuK6sTkIm22o9BFBCLtikWV5ryBW2YgohCFMvSxVIBK1W8vPI9YrVZvIwTHHFalofA66ajKXJ3ptsEuvoc/+vFPiHGYHOULSPfNF+D7JwblpXx5LfTB39Pln+otn8ds8P52b3YHhw6Be9gdHDoE7mF3cOgQtDdcttag7GrTt9Oa2Hfcwdmyuuzsqyde5j6I+5w+J/2/KoSfxlX2TxFFKkCzPkRyHmUo+9yXlIJ/S1leI0jBNkpVOY/sGoc15ksyfDEUZp8vqXTpCQQFoxD22ggr0coqzyMQvHTpXiLp2+v1gQb434HA+iIXiGhEhtWWy7ym0dvXK/qWFllQFAUzdWgxzkv70fhRLGH45DiDYpGKNmvUMWON/x5Q88By35GovC6rcN0rqu5ePMXHvXf/QdigvK+SEFrcozTfCdYIKnAPVxT1m0rx/Zgry/Bkf+s+2IB5c292B4dOgXvYHRw6BG0144OBAI20dMUOX3ed6IukmK46e/as6EPz5QJ1R0SUXZNFaFagZJI2W9FtwKyuvq5uMQ717ItKJx1NUDQxi1U5Lgc6ZYqtonoRogFVZl4XUIfWAG1mJAWIZmauIOkZkUW2gbwn0mb6XElzmu1CTUWGIVsOswWJpCuGmViaUtQRdQgd5QYzXPc7evu4DSMiJ+W4KJTx1pljDdyGEti49ZZbvPYH7v0Fr31+VurHWYi4jCiqtmbZv9g+MuK1X33xRTEO9ekuOgM6zPIScG92B4cOgXvYHRw6BG0148PRCO29rlUGR628Lmd4BbsnKZP7Bwf2ee0U6JnNzSlTySx57aqWZiuzaWYh+mghJzXLkhFeNdUy00Ew4QyUNMpmZPSYbbBZpnI2KJ6AKCi1il+EqLxecF18ytStw/wLRbkqW4FVZS1YgQjCOC1H7YO7IhRil6FalmZ8FUzhmpLM1gIQ3rbVdfGhQapl8ujSZre2/HFfuKpOJJmGKrgr8XhCjIuF+aCXl5dFXwl0Chtq588+9rjX/sRHP+610z0yUSWJ11PfmxU+r+dBPjrRLd3U6dlJrx0OSf3CQiuBS5foQrg3u4NDh8A97A4OHQL3sDs4dAjaG0HXsJRriTlMT0+JvkOHrvLalZj0lUNQYvnMJNNr/dulMGUJKK8qiD8QEa2WwA+z7CNpGgTLHem+JcjYKq/wuLKKqkIfMqAcNMxEi4Tk6a81ePv5Iq9hxGNSGKIAWV4JHSlYgnLLsE6hKS4U56wo+q5S5zlXSzxf45e0kwFfU0fGlWHfiQTTTnodpArTUgFjhNLuOH8tKoJUYVWRUkijJWH9IagWCBbm+X7RmW0B2L5V2WYlyDr8zve+67WHd8jyTDj/dFIKWyA9GIIsQL+KsIwE+VpHAvK6x1rlqDeKhtxsffYxIspSc8mnZq09YozpJaKvEtEuIhojog9ba1fW24aDg8PW4qcx499hrb3BWnuk9fnTRHTUWrufiI62Pjs4OLxB8VrM+HuJ6M5W+35q1oD71EZf8Af81NsqaWNrkpoYgqT9ojI5F1ZZk+5d/+S9XruqhSfo3V77//2vfyr66mBWNkBwoKZM8LphU7WoqKYk6NrVgSarK61yA6ZkXWncGeAECxXNy/HliEHyS6UoI7qiUIYppEohrYGrgSWOUEuOiCgHwggXRbGh2QrtRk2a++iu1DfQKy+Ae2VUCSmsOmoUTymi3MQclXADzle5AhHQ38e7fTW3Ksb5gHqrlFUUHujXV1XUYwBo1rGxc1471btNjBsa5Hlk8jLa8MAeNvmTa0zj1tR9FY0yXRj2S3dl5oJbrE8AYLNvdktEf2eMedoYc1/rb4PW2hkiotb/A5vcloODwxZgs2/2262108aYASJ6xBjz6mZ30PpxuI+IqFfVMXdwcGgfNvVmt9ZOt/6fJ6JvEtEtRDRnjBkmImr9P7/Odz9vrT1irT2SSKUuNcTBwaENuOyb3RgTJyKftTbbar+biP4NET1ERB8jos+2/n/wctuq1+q0vNoMTw1FJP2AgnyZ5SXRV4WsoMWxM9xRkuGmORCgTPbJktBIkazMM+1XVT5OCai3eFRSTQik5WpKG15nhyHQL/X55L6RrloBPzSgfNl+yPyrZ3VMLPjYsHmf8v8aunDbevMFX/misF0hPCG/J/e3Qa03u37I7XoZcfrvRujjrz/W+PmeCyjxlDLowTcaKnwYSoYbLdwJVOoalJW++51vFeMmp/iei0VlqCvq769APbdYl3w5njnNawJD/TKUttqiYzcKl92MGT9IRN9snbQAEX3ZWvttY8xTRPSAMeYTRDRORB/axLYcHBy2CJd92K21Z4no8CX+vkRE77z4Gw4ODm9EtDWCzu8z1NUSCSisSOpjYNswf1CKDw1Iw7rp2mu8dj4ns5OOfu9HXntUlbsdP8vmfx7qCgUVlZIG06lQlFTTSpY/96dZ9KKiKCk0petGUW/ABEXD0pyrQRmmIrgCahPkB020tFoHKUDZ40J9/XJHaHdvpFEvv6LNanRJVEkmYe6ub1piSSmjMtZEWekNRC42Gof66jVIA/SriL+QZRO/qK57FdMH1TSiCXap9u/lKNCnn3hOjLvmBn5fnps4J/oO7OZ7ddfunV77qWefFeMGoBR4NpsVfb6WS2U3uJYuNt7BoUPgHnYHhw6Be9gdHDoEba/1NtBS33hSiUpmT5zy2rGgpEVSoBAz3WCfNK+UXnqHWazvgKIm3vNuXkucmuJSuL1pSdF95asPeO1XX5I+UzrG9IwP6sX1dEnVkxJof+crUkkmEgDRShXC2gDfswL+u9YSDIJKzlJJhgwboF4wnLWqwoJ9sFGtKoM+/Hrikxpa850297WLv4df20gEHYDz18cyMMCBnft3s0997MWXxbgiaPEbFYKMWZd6fQOFNe+66x1ee/eOHWLcAqjfhEJyveDcOfbhz8H2b7r5ZjEOBSfPnz4t+mItKnt9kU73Zndw6Bi4h93BoUPQVjO+Xm/QWq5Ja6QHZVZQD1BeARVZ1hXkJP4L3yci6uqWuTehKGfO9aoIPV8dhCEyHKmW7pcm1a/86q977eWJO0TfKxPHvfYPH+SAwWxemurxKItNlFX5JyzP5A9JkzMO5ZWiMW5rc7ZK4L4oKzgYYZenDGKUQU2NgWpEfZPUm54H0jw+VbIL+yyUfdaGudiG6kO3RngFqvxTXcxDXs+VtTWvPT1xHvYlKVecv18JQPgDvP3euBKSHOD7eAki4bYP7RTj+nqGvHY4Ie+JlcVZr51OsNhqRIloVInN+MHREdnXEhIxfmfGOzh0PNzD7uDQIWirGV+p1Whisakhp5WyYpBYMn1ertTXYUUVE/rPnDolxh3ay/ryi2uLom8VdOlH9nDE0vj582Lcu95+u9c+tSoj9HyGo+bC/bu89lJGZvw2KmxmB4LySLHMUCErNevTqX6vnYPEjFJFJtYEAmyqB5UuXAmELhpgqjd0hVShw76BaAR+R6+cYzml+voJOeJ7yo5HvTddhgorsuKcGuod5V9nHBFRDaIxx+Y4GaUrLmsTRKFibyIh2ZUyMh4BGfX42//8X3rtZJzdt4m5CTEuGmO30qrHLgqJMXgsx556SozLlvg+GB6RZvyeHaPN6fnXf6Tdm93BoUPgHnYHhw6Be9gdHDoE7c168/sokWr6Q2EjfauVFdaD375X6sGfOsEZazbIvk93TPpPiSBHiXWlZSnmsXH21/bu5+0XMnLcyhr7rkMoZQAADI9JREFU9l2K3jgMmVKpLva9//xzcu2gAYIMIaU9nweBCl9Y9q3mQEABfE2jVjhyWR5Xp/XrxdEG4hXop2sxSrNu+d/Nl1tG+MCPbKh91dYVlZR+bh26TEX69ujz6nWFEmQBhqFscr4m10H6QMs915DU2OFb3+a1P/yBXxR9c1PTXrtrD/v9A2kpwTY9zeMaKkJv57btXjsBazp74wfFuEgc5qhKZB97uunf55UuP8K92R0cOgTuYXdw6BC01Yw3ZLyooGxmTfTt6OeElOcU5TAHulxxMNn23Hi9GFcqsAk7vjAj+vaB6V5b4X0fUBTGCUjQaShzdmmZTaRtgxwh9Xv/4T+KcZ/7kz/22pPnx0VfAE55va606+Bq+LEkdFaWhEZ6CUtGERGhtY5Satq8Ra2yTVrjF+nMIb12UXQdRr/VNxBUgMSNpBLi6IbS3RkwTysNVaYaEqLiMUmb+cN8Hv/z//NfvXYsLktqjZ086bVTCdl3+KZbeb6K2qtcfbXXPn6cIywHUpLaQzrPqLJO+Txf30iQz4e18vFcXOGCSxWl0z/YEn/RZbgQ7s3u4NAhcA+7g0OHwD3sDg4dgrYLTqZaPlQk1SX6Xjl5wmsPjchyt9v28m9Sfp5rUQwMyQykR59gXx/F/4iIIqATPjfDNEhBUTAGRCAH+mRW3d49fLomz3M4ZL4gt/HhX/uE116AjCYioq9/5Uteu5GXNEmhzL5oATTwfeo3uWFR6HF98Qf0sfWoDX/lUUsfXHFN3yE2FISEnem1AxQBqVSk0GMswLRoHbL5/GobgRB/rimxUgxNrRX5OvVs6xXjlgY4K20U2kREeaBEK6omgA/q6XV38T2tRTQCkI2XSMt9L8xxLcNuH/vz01Ny3Wl4gOk8X0CuHRTLl89cdG92B4cOgXvYHRw6BO3NeqtU6PzkJBFdXCKpd4Qz0SIxSU3UCmzS7tjDFNpjj/1EjLvh8I28jYjcxtoCR+jt23fAa5+fnhLjAqB/F1PbmJvhsUuQsdY9NCzG+YNsjqZUBN1//MP/5LV/79/+n6KvPMsmf4ywhLA09zGzqbZBiV5jsDzT5so9EREZMNc31GRH0QilfbZZzfcguFdaNGIZ6FksmVRW4iYE5Znq6jh/63f+ldceH2caNNkjIye3d7NpPTY9KfpGR1hPrlyWtF8swFFtyyCUsSspqTc8BbqEVAOzGqHEdyEv6WkK8X2WycmMyQvnx2zgam3qzW6M6TbGfM0Y86ox5rgx5s3GmF5jzCPGmFOt/3suvyUHB4etwmbN+D8hom9baw9SsxTUcSL6NBEdtdbuJ6Kjrc8ODg5vUGymimuKiN5ORL9ORGStrRBRxRhzLxHd2Rp2PxE9SkSf2mhb1lrPfE92yUSBKiQ3JAMyKqw7waucxyHCbdu+Q2JcLs/fW12RwhNxiFo6OcbmXERV1AyCzG9QVRVdW2HTqWeItcfW8jIpoQGVPbuVuMRgmld67/v4faJvG5TAKoJ4xQ8fe1SM+8Zff9Nr+5TgQzHH0YYBs76og4XMEqvX6qEMk5820KrDZBrlThgw69HE16vUfpS01qIUYNZXqhwx5ldVVqsw37e9822i79DVXC5scVKubiNysH2fMrOTIXbFTr5yXPQN7eQIzFgCtQeluZ8BEz+opNLxzM2AW7ltQLJBh4Fh+uHcj0WfP9I8d2YD3e7NvNn3ENECEf25MeZZY8x/b5VuHrTWzhARtf4f2GgjDg4OW4vNPOwBIrqJiD5nrb2RiPL0U5jsxpj7jDHHjDHHCvn85b/g4ODwumAzD/skEU1aa59sff4aNR/+OWPMMBFR6//5S33ZWvt5a+0Ra+0RnXzg4ODQPmymPvusMWbCGHOVtfYENWuyv9L69zEi+mzr/wc32ExzW2So3Cq/3BVVQomrnNHjT0mP4NS5Ma8dAQECf12LKLLP7lcldpahxG0ZRA4LRelvD4eZVJiYnxN9VfAv5yfZt9oxJEtI4aHt3S2FOL7z6Pe99jVHbhJ9JYjU2jO6i7f3jneLcXfdyZ+nZ+Vv7I5tPJcvf/UrXvuJJ54Q43w19im1H50rcB/eIKWyXEsRIpDKn/eBfjmWSNI0XACuRUhlbAV9fCIx0jHvl9mCv/bRf+a1rzsooy97QEiykuLzq6lfpApLRZ1Vx/78SEvY8QJqcA92x5huwyhNIqLuLqb6ysrCXVhicdQdvbyWleiW9OADD/JajdaNX8w07+PqRcKfjM3y7P+CiL5kjAkR0Vki+jg1rYIHjDGfIKJxIvrQJrfl4OCwBdjUw26tfY6Ijlyi652X+JuDg8MbEG2NoGs0GlTKNU2kpYqMUtq/h3W4xidlX6yHo5uSQJUFVRJIGfTaFxZXRN/gDhabqM1z305lDs0tsuleVW5CGPTBuiC6rrQoab6+HXwsRaVndu2NN3jt+RllggPV0p1g8/O7339UzgPM3Rtve5Po6wEttffcxb/FB3fvl/M4woIMf//jx0RfNMjHfaHqLhHRiy+/JMb5QGjhqSeeFH3lIkcR2nWrwsqIt6sOXiP63g16b295K1Nqf//d74txfaA3WCuvrxs/OsomuKZLsfJuV69MsHru1GnokwlcDctuyOIMR0CuzUqa7647ucLrsWPHRF8Armd8kGsHjI2NiXFX7+Uo0/lVeX8HWudYR+chXGy8g0OHwD3sDg4dAvewOzh0CNorOOn3UbirybWnuySt8NSrHAYbi8lyy40yUy3FPNMU8aSqyZVnP3FxRQohJHuZaqkDLffScRn+GImwD9Y/JP35CdAIj0XZfw/1yAynGujBP/eS3H4chAh7+2XIcLnKx/nMM8947Ztuu1WMO32SfchiVVItgQX2RQeGOTR3KSfHZYBe27tf6pMnQjJT7wJujkpByP7tTPPdfMudoq8ONOheyFR8/ukXxLhD13EIaDgo4zB6e/keaeT53OxWdQVWQIhx155dom8BxE6wXkBtVZ6PsXEWI0n3Syo1DAIV29KyLwt0aa7K5zQG6zZERE8d4wzNW990s+ibWF712lXQ/de17ybn+FhCUfnoZlYLre9sIO65bo+Dg8M/KriH3cGhQ2B+GlGD17wzYxaI6DwR9RHR4mWGtwNuHhJuHhJvhHn8tHPYaa3tv1RHWx92b6fGHLPWXipIx83DzcPN43WagzPjHRw6BO5hd3DoEGzVw/75LdqvhpuHhJuHxBthHldsDlviszs4OLQfzox3cOgQtPVhN8bcY4w5YYw5bYxpmxqtMebPjDHzxpiX4G9tl8I2xowaY77fkuN+2Rjzya2YizEmYoz5iTHm+dY8fn8r5gHz8bf0DR/eqnkYY8aMMS8aY54zxhzbwnm8brLtbXvYjTF+IvovRPRPiOhqIvqIMebqjb91xfAFIrpH/W0rpLBrRPTb1tpDRHQbEf1G6xy0ey5lIrrLWnuYiG4gonuMMbdtwTwu4JPUlCe/gK2axzustTcA1bUV83j9ZNuttW35R0RvJqLvwOfPENFn2rj/XUT0Enw+QUTDrfYwEZ1o11xgDg8S0d1bORciihHRM0R061bMg4hGWjfwXUT08FZdGyIaI6I+9be2zoOIUkR0jlpraVd6Hu0047cT0QR8nmz9bauwpVLYxphdRHQjET25FXNpmc7PUVMo9BHbFBTdinPyx0T0OyTl07diHpaI/s4Y87Qx5oKgf7vn8brKtrfzYb+Uen1HUgHGmAQRfZ2IftNam7nc+NcD1tq6tfYGar5ZbzHGXNvuORhj3kdE89bap9u970vgdmvtTdR0M3/DGPP2LZjDa5Jtvxza+bBPEhFKc44Q0fQ6Y9uBTUlhX2kYY4LUfNC/ZK39xlbOhYjIWrtKzWo+92zBPG4novcbY8aI6C+J6C5jzBe3YB5krZ1u/T9PRN8kolu2YB6vSbb9cmjnw/4UEe03xuxuqdT+UyJ6qI3713iImhLYRJuUwn6tME0d5f9BRMettX+0VXMxxvQbY7pb7SgRvYuIXm33PKy1n7HWjlhrd1Hzfvietfaj7Z6HMSZujEleaBPRu4nopXbPw1o7S0QTxpgLSf4XZNuvzDxe74UPtdDwHiI6SURniOhft3G/XyGiGSKqUvPX8xNElKbmwtCp1v+9bZjHW6npurxARM+1/r2n3XMhouuJ6NnWPF4iov+j9fe2nxOY053EC3TtPh97iOj51r+XL9ybW3SP3EBEx1rX5q+JqOdKzcNF0Dk4dAhcBJ2DQ4fAPewODh0C97A7OHQI3MPu4NAhcA+7g0OHwD3sDg4dAvewOzh0CNzD7uDQIfj/Abdz/pRND/xHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize another example\n",
    "plt.imshow(X[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data Into Train And Test Sets <a acnhor = \"anchor\" id = \"7.2\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rorder the data \n",
    "random.shuffle(X)\n",
    "random.shuffle(Y)\n",
    "\n",
    "#define the size of the training set \n",
    "train_size = int(X.shape[0] * 0.8)\n",
    "\n",
    "#Split the data into 80%  train set and 20% test set\n",
    "train_X = X[: train_size ] \n",
    "train_Y = Y[: train_size]\n",
    "test_X  = X[train_size: ]\n",
    "test_Y =  Y[train_size: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train_X: (6400, 64, 64, 3)\n",
      "The shape of train_Y: (6400,)\n",
      "The shape of test_X: (1600, 64, 64, 3)\n",
      "The shape of the test_Y: (1600,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"The shape of train_X: {train_X.shape}\\nThe shape of train_Y: {train_Y.shape}\\nThe shape of test_X: {test_X.shape}\\nThe shape of the test_Y: {test_Y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten the data so we can feed them to our neural network model \n",
    "train_X_flatten = train_X.reshape(train_X.shape[0], -1).T\n",
    "test_X_flatten = test_X.reshape(test_X.shape[0], -1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data to have feature values between 0 and 1.\n",
    "train_X = train_X_flatten /255\n",
    "test_X = test_X_flatten /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train_X: (12288, 6400)\n",
      "The shape of test_X: (12288, 1600)\n"
     ]
    }
   ],
   "source": [
    "print(f\"The shape of train_X: {train_X.shape}\\nThe shape of test_X: {test_X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train_Y: (1, 6400)\n",
      "The shape of test_Y: (1, 1600)\n"
     ]
    }
   ],
   "source": [
    "#Reshape train_Y, test_Y to be row vectors \n",
    "train_Y = train_Y.reshape(1,train_Y.shape[0])\n",
    "test_Y = test_Y.reshape(1, test_Y.shape[0])\n",
    "\n",
    "print(f\"The shape of train_Y: {train_Y.shape}\\nThe shape of test_Y: {test_Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "## Architecture of The Model  <a anchor = \"anchor\" id = \"7.3\"> </a>\n",
    "\n",
    "<br>\n",
    "\n",
    "### 2-Layer Neural Network <a anchor = \"anchor\" id = \"7.31\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define some constants needed to construct the model \n",
    "n_x = 12288 #number of units in the input layer\n",
    "n_h = 7     #number of units in the hidden layer\n",
    "n_y = 1     #number of units in the output layer\n",
    "layers_dims = (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost = False):\n",
    "    '''\n",
    "    Usage:\n",
    "      #two_layer_model --> used to construct two layer model \n",
    "  \n",
    "    \n",
    "    Arguments:\n",
    "      #X --> input data, of shape (n_x, number of examples)\n",
    "      #Y --> true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "      #layers_dims --> dimensions of the layers (n_x, n_h, n_y)\n",
    "      #num_iterations --> number of iterations of the optimization loop\n",
    "      #learning_rate --> learning rate of the gradient descent update rule\n",
    "      #print_cost --> If set to True, this will print the cost every 100 iterations \n",
    "\n",
    "    \n",
    "    Returns:\n",
    "      #parameters --> a dictionary containing W1, W2, b1, and b2\n",
    "          1. Initialize parameters / Define hyperparameters\n",
    "2. Loop for num_iterations:\n",
    "    a. Forward propagation\n",
    "    b. Compute cost function\n",
    "    c. Backward propagation\n",
    "    d. Update parameters (using parameters, and grads from backprop) \n",
    "4. Use trained parameters to predict labels\n",
    "      \n",
    "    '''\n",
    "\n",
    "\n",
    "    #initialize some variables will be populated later \n",
    "    np.random.seed(1)\n",
    "    grads = {}\n",
    "    costs = []\n",
    "    m = X.shape[1]\n",
    "    (n_x, n_h, n_y) = layers_dims\n",
    "    \n",
    "    #1. Initialize parameters / Define hyperparameters\n",
    "    parameters = initialize_parameters(n_x,n_h,n_y)\n",
    "    \n",
    "    #Get the parameters from the intialized dicationary , parameters\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    \n",
    "    #2. Loop for num_iterations:\n",
    "    for i in range(0, num_iterations):\n",
    "        \n",
    "        #a. Forward propagation\n",
    "        A1, cache1 = linear_activation_forward(X, W1, b1, activation='relu')\n",
    "        A2, cache2 = linear_activation_forward(A1, W2, b2, activation='sigmoid')\n",
    "        \n",
    "        #b. Compute cost function\n",
    "        cost = compute_cost(A2, Y)\n",
    "        \n",
    "        #c. Backward propagation\n",
    "        dA2 = - (np.divide(Y, A2) - np.divide(1 - Y, 1 - A2))\n",
    "        dA1, dW2, db2 = linear_activation_backward(dA2, cache2, activation = \"sigmoid\")\n",
    "        dA0, dW1, db1 = linear_activation_backward(dA1, cache1, activation = \"relu\")\n",
    "        \n",
    "        #Populate grads dic \n",
    "        grads[\"dW1\"] = dW1\n",
    "        grads[\"db1\"] = db1 \n",
    "        grads[\"dW2\"] = dW2\n",
    "        grads[\"db2\"] = db2\n",
    "        \n",
    "        #d. Update parameters \n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        #4. Get the new parameters form paramters dic \n",
    "        W1  = parameters[\"W1\"]\n",
    "        b1 = parameters[\"b1\"]\n",
    "        W2 = parameters[\"W2\"]\n",
    "        b2 = parameters[\"b2\"]\n",
    "        \n",
    "        #Print the cost every 100 examples \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "            costs.append(cost)\n",
    "        \n",
    "        \n",
    "    #Plot the cost \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel(\"cost\")\n",
    "    plt.xlabel(\"number of iterations\")\n",
    "    plt.title(f\"learning rate = {learning_rate}\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L-Layer Neural Network <a anchor = \"anchor\" id = \"7.32\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    '''\n",
    "    Usage:\n",
    "      #L_layer_model --> used to construct L-Layer Model\n",
    "  \n",
    "    \n",
    "    Arguments:\n",
    "      #X --> input data, of shape (n_x, number of examples)\n",
    "      #Y --> true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "      #layers_dims --> list containing the input size and each layer size, of length (number of layers + 1).\n",
    "      #num_iterations --> number of iterations of the optimization loop\n",
    "      #learning_rate --> learning rate of the gradient descent update rule\n",
    "      #print_cost --> If set to True, this will print the cost every 100 iterations \n",
    "\n",
    "    \n",
    "    Returns:\n",
    "      #parameters --> a dictionary containing W1, W2, b1, and b2\n",
    "      \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    #1. Initialize parameters / Define hyperparameters\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    \n",
    "    #2. Loop for num_iterations:\n",
    "    for i in range(0, num_iterations):\n",
    "        \n",
    "        #a. Forward propagation\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        \n",
    "        #b. Compute cost function\n",
    "        cost = compute_cost(AL, Y)\n",
    "        \n",
    "        #c. Backward propagation\n",
    "        grads =  L_model_backward(AL, Y, caches)\n",
    "        \n",
    "        #d. Update parameters\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating The Parameters <a anchor = \"anchor\" id = \"8\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693173\n",
      "Cost after iteration 100: 0.693127\n",
      "Cost after iteration 200: 0.693103\n",
      "Cost after iteration 300: 0.693087\n",
      "Cost after iteration 400: 0.693071\n",
      "Cost after iteration 500: 0.693055\n",
      "Cost after iteration 600: 0.693036\n",
      "Cost after iteration 700: 0.693013\n",
      "Cost after iteration 800: 0.692983\n",
      "Cost after iteration 900: 0.692944\n",
      "Cost after iteration 1000: 0.692894\n",
      "Cost after iteration 1100: 0.692829\n",
      "Cost after iteration 1200: 0.692745\n",
      "Cost after iteration 1300: 0.692639\n",
      "Cost after iteration 1400: 0.692510\n",
      "Cost after iteration 1500: 0.692355\n",
      "Cost after iteration 1600: 0.692172\n",
      "Cost after iteration 1700: 0.691959\n",
      "Cost after iteration 1800: 0.691718\n",
      "Cost after iteration 1900: 0.691453\n",
      "Cost after iteration 2000: 0.691166\n",
      "Cost after iteration 2100: 0.690862\n",
      "Cost after iteration 2200: 0.690542\n",
      "Cost after iteration 2300: 0.690210\n",
      "Cost after iteration 2400: 0.689864\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Updating using L-layer model \n",
    "parameters = L_layer_model(train_X, train_Y, layers_dims, num_iterations = 2500, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.6931466185441809\n",
      "Cost after iteration 100: 0.6931346282195124\n",
      "Cost after iteration 200: 0.6931262175570102\n",
      "Cost after iteration 300: 0.6931200466848827\n",
      "Cost after iteration 400: 0.6931152278775053\n",
      "Cost after iteration 500: 0.6931111154295272\n",
      "Cost after iteration 600: 0.6931069721017076\n",
      "Cost after iteration 700: 0.693102318276958\n",
      "Cost after iteration 800: 0.693096967075716\n",
      "Cost after iteration 900: 0.6930902461075581\n",
      "Cost after iteration 1000: 0.6930816652060476\n",
      "Cost after iteration 1100: 0.6930704755309737\n",
      "Cost after iteration 1200: 0.6930557473019582\n",
      "Cost after iteration 1300: 0.6930362652684329\n",
      "Cost after iteration 1400: 0.6930106484159012\n",
      "Cost after iteration 1500: 0.6929771817736541\n",
      "Cost after iteration 1600: 0.6929336956394806\n",
      "Cost after iteration 1700: 0.6928778345120196\n",
      "Cost after iteration 1800: 0.6928067116521899\n",
      "Cost after iteration 1900: 0.6927169395314293\n",
      "Cost after iteration 2000: 0.6926059798536699\n",
      "Cost after iteration 2100: 0.6924710875558253\n",
      "Cost after iteration 2200: 0.6923102782372773\n",
      "Cost after iteration 2300: 0.692122785888319\n",
      "Cost after iteration 2400: 0.6919102409485887\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Updating using 2-layer model\n",
    "parameters2 = two_layer_model(train_X, train_Y, layers_dims = (n_x, n_h, n_y), num_iterations = 2500, print_cost=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing The Accuracy  <a anchor = \"anchor\" id = \"9\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53296875\n"
     ]
    }
   ],
   "source": [
    "predictions_train = predict(train_X, train_Y, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.508125\n"
     ]
    }
   ],
   "source": [
    "predictions_test = predict(test_X, test_Y, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
