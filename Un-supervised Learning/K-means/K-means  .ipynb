{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style = \"text-align:center\"> K-means Clustering Algorithm</h1>\n",
    "\n",
    "\n",
    "## About the data\n",
    "the data about <strong>Mall Customers</strong> and we are trying to divide the customers into k-groups based on feature similarity.\n",
    "We might subdivide the Customers in 5 distinct groups:\n",
    "1. Medium Annual Income, Medium Spending Score\n",
    "2. High Annual Income, Low Spending Score\n",
    "3. Low Annual Income, Low Spending Score\n",
    "4. Low Annual Income, High Spending Score\n",
    "5. High Annual Income, High Spending Score\n",
    "\n",
    "## Attribute Detailes\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th style=\"text-align:center\" >Name</th>\n",
    "     <th style=\"text-align:center\">Type</th> \n",
    "    <th style=\"text-align:center\">Description</th>\n",
    "   </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center\">CustomerID</td>\n",
    "     <td style=\"text-align:center\">Integer</td> \n",
    "    <td style=\"text-align:center\" >A user identification number for a customer</td>\n",
    "   </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center\">Genre</td>\n",
    "     <td style=\"text-align:center\">String</td> \n",
    "    <td style=\"text-align:center\" >A gender: the fact of being male or female</td>\n",
    "   </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:center\">Age</td>\n",
    "     <td style=\"text-align:center\">Integer</td> \n",
    "    <td style=\"text-align:center\">The age of the customer</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "    <td style=\"text-align:center\">Annual Income</td>\n",
    "     <td style=\"text-align:center\">Integer</td> \n",
    "    <td style=\"text-align:center\">An income calculated over a period of one year in dollars</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "    <td style=\"text-align:center\">Spending Score (1-100)</td>\n",
    "     <td style=\"text-align:center\">Integer</td> \n",
    "    <td style=\"text-align:center\">A score assigned by the mall based on customer behavior and spending nature.The higher the Spending Score (out of 100), the more they spend at the Mall.</td>\n",
    "   </tr> \n",
    "</table>\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the important libraires \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import math\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data set\n",
    "df = pd.read_csv(\"Mall_Customers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the top five of the data \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the last five of the data \n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the data types in the data set\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the shape of the data \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the number of training examples \n",
    "m = df.shape[0]\n",
    "\n",
    "print(\"The number of training examples:\",m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the data set to numpy-array so we can feed it to our model\n",
    "X = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the converted data set in numpy-form\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visulaize the 5-distinct groups\n",
    "plt.scatter(X[:,-2], X[:,-1],color = 'r')\n",
    "plt.scatter(X[:,-2] >= 40, X[:,-1] >= 80 ,color = 'b')\n",
    "\n",
    "plt.xlabel(\"Annual Income (k$)\")\n",
    "plt.ylabel(\"Spending Score (1-100)\")\n",
    "plt.title(\"The relation between Spending Score and Annual Income\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p style = \"font-size:18px\">We can see that we can divide the data into 5 groups based on its feature similarity.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Define Some Helper Functions\n",
    "\n",
    "\n",
    "<br>\n",
    "<dl>\n",
    "   <dt>featureNormalize()</dt>\n",
    "  <dd>For feature scalling </dd>\n",
    "    <dt>findClosestCentroids()</dt>\n",
    "  <dd>For computing the centroid memberships for every example</dd>\n",
    "  <dt>computeCentroids()</dt>\n",
    "  <dd>For Computing centroid means </dd>\n",
    "   <dt>kMeansInitCentroids()<dt>\n",
    "    <dd> For initializing centroids</dd>\n",
    "  <dt>oneHot()</dt>\n",
    "  <dd>For for encoding the data</dd>\n",
    "  <dt>kMeans()</dt>\n",
    "  <dd>For building the k-means clustering algorithm<dd>\n",
    "    <dt>lowestCost()</dt>\n",
    "    <dd>For computing the lowest cost </dd>\n",
    "</dl>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.featureNormalize()\n",
    "The result of standardization (or Z-score normalization) is that the features will be rescaled so that they’ll have the properties of a standard normal distribution with\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\largeμ=0 \\hspace{2cm}  σ=1\n",
    "\\end{align}\n",
    "\n",
    "<strong>where ,</strong>\n",
    "\n",
    "$\\normalsize \\mu:$ is the mean (average) \n",
    "\n",
    "$\\normalsize\\sigma:$ is the standard deviation from the mean; standard scores (also called z scores) of the samples are calculated as follows:\n",
    "\n",
    "\\begin{align}\n",
    "\\large z=\\frac{x - μ} {σ}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureNormalize(X):\n",
    "    '''\n",
    "    Usage:\n",
    "      #featureNormalize--> used for normalizing features using Z-score normalization\n",
    "  \n",
    "    Arguments:\n",
    "      #X --> The Design Matrix\n",
    "    \n",
    "    Returns:\n",
    "      #The Normalized Matrix\n",
    "      \n",
    "    Notes:\n",
    "      #X is a matrix where each column is a feature and each row is an example\n",
    "      #So, you need to perform the normalization separately for each feature\n",
    "    '''\n",
    "    \n",
    "    #Preallocating some variables to be used later \n",
    "    X_norm = np.copy(X)\n",
    "    mu = np.zeros((1, X.shape[1]))\n",
    "    sigma = np.zeros((1,X.shape[1]))\n",
    "\n",
    "    #compute the mean of the feature and subtract it from the dataset, storing the mean value in mu\n",
    "    #Next, compute the standard deviation of each feature, storing the standard deviation in sigma.\n",
    "    for i in range(X.shape[1]):\n",
    "        mu[0, i] = mu[0, i] + np.mean(X_norm[:, i])\n",
    "        sigma[0, i] = sigma[0, i] + np.std(X_norm[:, i])\n",
    "        \n",
    "    #Finally, compute the standard deviation of each feature and divide each feature by it's standard deviation, storing the result in x_norm\n",
    "    for i in range(X.shape[1]):\n",
    "        X_norm[:, i] = np.divide(np.subtract(X_norm[:, i], mu[0, i]), sigma[0, i])\n",
    "        \n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.findClosestCentroids()\n",
    "\n",
    "In the <strong>\"cluster assignment\"</strong> phase of the K-means algorithm, the algorithm\n",
    "assigns every training example $x^{(i)}$ to its closest centroid, given the current\n",
    "positions of centroids.\n",
    "\n",
    "Given training examples (data points) and the current centroids we find , for every training example $x^{(i)}$, $c^{(i)}$ which is the index  of the centroid that is closest to $x^{(i)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findClosestCentroids(X,centroids): \n",
    "    '''\n",
    "    Usage:\n",
    "      #findClosestCentroids--> computes the centroid memberships for every example\n",
    "  \n",
    "    Arguments:\n",
    "      #X --> The Design(data) Matrix\n",
    "      #centroids --> the locations of all centroids\n",
    "    \n",
    "    Returns:\n",
    "      #idx --> a one-dimensional array, idx, that holds the index (a value in {1,....,K} \n",
    "               where K is total number of centroids) of the closest centroid \n",
    "               to every training example.\n",
    "    '''\n",
    "    \n",
    "    #Define K which is the total number of centroids\n",
    "    K = centroids.shape[0]\n",
    "    \n",
    "    #Pre-allocating idx which has size of (#training examples,1)\n",
    "    idx = np.zeros((X.shape[0],1), dtype = np.int8)\n",
    "    \n",
    "    #iterating over every training example \n",
    "    for i in range(X.shape[0]):\n",
    "        \n",
    "        #Pre-allocating distance_array with size(K,)\n",
    "        #distance_array: is array holding distance between the training example , x[i], \n",
    "        #and the all the centroids in  the centroids array\n",
    "        distance_array = np.zeros((K,))\n",
    "        \n",
    "        #iterating over all the centroids in the centroids array \n",
    "        for j in range(K):\n",
    "            \n",
    "            #Compute the distance between the training example X[i] and the centroid with index j\n",
    "            #then, store the result in the distance_array\n",
    "            distance_array[j] = np.power(np.linalg.norm(X[i] - centroids[j]),2)\n",
    "            \n",
    "            \n",
    "        #find the index of  minmum distance in the distance_array \n",
    "        #corresponding to the training example, x[i]\n",
    "        #then, store the result in the idx \n",
    "        idx[i] = np.argmin(distance_array, axis = 0)\n",
    "        \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.computeCentroids()\n",
    "\n",
    "Given assignments of every point to a centroid, the second phase of the\n",
    "algorithm recomputes, for each centroid, the mean of the points that were\n",
    "assigned to it. Specifically, for every centroid k we set\n",
    "\n",
    "\\begin{equation}\n",
    "\\large \\mu_k := \\frac{1}{|C_{k}|} \\sum_{i \\in C_{k}} {x^{(i)}}\n",
    "\\end{equation}\n",
    "\n",
    "<strong>where,</strong>\n",
    "<br>\n",
    "$ \\normalsize\\mu_{k}:$ The mean of of the data points assigned to the centroid k\n",
    "\n",
    "$\\normalsize C_{k}:$ is the set of examples that are assigned to centroid k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCentroids(X,idx,K):\n",
    "    '''\n",
    "    Usage:\n",
    "      #findClosestCentroids--> computes the new centroids by computing \n",
    "                               the means of the data points assigned to \n",
    "                               each centroid.\n",
    "    Arguments:\n",
    "      #X --> The Design(data) Matrix\n",
    "      #idx --> a one-dimensional array, idx, that holds the index (a value in {1,....,K} \n",
    "               where K is total number of centroids) of the closest centroid \n",
    "               to every training example.\n",
    "      #K --> the total number of centroids\n",
    "    \n",
    "    Returns:\n",
    "      #centroids --> the new centroids by computing the means of\n",
    "                     the data points assigned to each centroid.\n",
    "                     \n",
    "    Notes: 1.centroids is  an array with size (k,#features of X)\n",
    "           2.below we use n.squeeze() to reduce the rank of idx so we can iterate over what it holds\n",
    "             Ex: idx = [[1,2,3]] --> [1,2,3] --> idx[0] --> 1\n",
    "           \n",
    "           \n",
    "    '''\n",
    "    #pre-allocating centroids with size (k,#features of X)\n",
    "    centroids = np.zeros((K,X.shape[1]))\n",
    "    \n",
    "    #iterating over every centroid and compute mean of all points that belong to it\n",
    "    for k in range(K):\n",
    "        \n",
    "        #define an empty list which will hold the data ponits coressponding to centroid k \n",
    "        dataPoints = []\n",
    "        \n",
    "        #iterating over all the training examples\n",
    "        for i in range(X_train.shape[0]):\n",
    "            \n",
    "            #if the index in idx equal to index k\n",
    "            if (idx[i] == k):\n",
    "                #append the value of index i wich belong to centroid k\n",
    "                #Note: we can use list with numpy array so we can append numpy-array to empty list\n",
    "                dataPoints.append(X[i])\n",
    "            \n",
    "        #after getting the data points that belong to centroid k \n",
    "        #first, we compute the mean of them \n",
    "        #then, store them in the centroids\n",
    "        #Note: we can applay numpy-methods to lists and the output is numpy-array\n",
    "        centroids[k,:] = np.mean(dataPoints, axis = 0)\n",
    "\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.kMeansInitCentroids()\n",
    "a good strategy for initializing the centroids is to select random examples from\n",
    "the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.computeCentroids()\n",
    "\n",
    "Given assignments of every point to a centroid, the second phase of the\n",
    "algorithm recomputes, for each centroid, the mean of the points that were\n",
    "assigned to it. Specifically, for every centroid k we set\n",
    "\n",
    "\\begin{equation}\n",
    "\\large \\mu_k := \\frac{1}{|C_{k}|} \\sum_{i \\in C_{k}} {x^{(i)}}\n",
    "\\end{equation}\n",
    "\n",
    "<strong>where,</strong>\n",
    "<br>\n",
    "$ \\normalsize\\mu_{k}:$ The mean of of the data points assigned to the centroid k\n",
    "\n",
    "$\\normalsize C_{k}:$ is the set of examples that are assigned to centroid k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeansInitCentroids(X,K):\n",
    "    '''\n",
    "    Usage:\n",
    "      #kMeansInitCentroids --> used for the initial assignments of centroids\n",
    "  \n",
    "    Arguments:\n",
    "      #X --> The Design(data) Matrix\n",
    "      #K --> the total number of centroids\n",
    "    \n",
    "    Returns:\n",
    "      #centroids -->  K initial centroids to be used with the K-Means on the dataset X\n",
    "    '''\n",
    "    \n",
    "    #pre-allocating centroids with size (k,#features of X)\n",
    "    centroids = np.zeros((K,X.shape[1]))\n",
    "    \n",
    "    #initialize the centroids to be random examples\n",
    "    #shuffle the indicies of the examples \n",
    "    randidx = np.random.permutation(X.shape[0])\n",
    "    \n",
    "    #take the first K-examples as centroids\n",
    "    centroids = X[randidx[:K],:]\n",
    "    \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.oneHot()\n",
    "\n",
    "In digital circuits, one-hot refers to a group of bits among which the legal combinations of values are only those with a single high (1) bit and all the others low (0). In this case, one-hot encoding means that if the feature is  \"Male\", then the output will be encoded as a vector of 2 elements with all elements being 0, except for the first element will be one.For the \"Female\", the output will be encoded as a vector of 2 elements with all elements being 0, except for second element will be one.\n",
    "\n",
    "<strong>The image below explain what i say easily for Gender feature</strong>\n",
    "\n",
    "<img src = \"https://i.imgur.com/BwguFW6.jpg\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHot(left,unencoded_input,right,width):\n",
    "    \n",
    "    '''\n",
    "    Usage:\n",
    "      #oneHot --> used for encoding the unencoded data\n",
    "  \n",
    "    Arguments:\n",
    "      #left --> the features which will be concatenated with encoded data from the left side\n",
    "      #unencoded_input --> the feature that will be encoded\n",
    "      #right --> the features which will be concatenated with encoded data from the right side\n",
    "      #width --> the width of the encoded data \n",
    "    \n",
    "    Returns:\n",
    "      #one_hot --> the one-hot-encoded data\n",
    "    '''\n",
    "    #reshape the data to be (#training examples,1) if it has size (#training examples,)\n",
    "    #Note: if the data has the size that we reshape this line will do nothing \n",
    "    #because we reshape the data with the same size \n",
    "    unencoded_input = unencoded_input.reshape(unencoded_input.shape[0],1)\n",
    "    \n",
    "    \n",
    "    #label-encoding the uncoded data\n",
    "    #replacing Male with one and the remaining , female  in our case, will be 2\n",
    "    label_encoding = np.where(unencoded_input == 'Male',1,2)\n",
    "    \n",
    "    #Pre-allocating a container to assign the encoded data to it \n",
    "    container = np.zeros((unencoded_input.shape[0],width))\n",
    "    \n",
    "    #Define an index,j, to assign the encoded data to  container \n",
    "    j = 0\n",
    "    \n",
    "    #loop over the label-encoded data\n",
    "    for i in label_encoding:\n",
    "        #if the i == [1] --> Male\n",
    "        if (i == [1]):\n",
    "            container[j,:] = [1,0] #represents Male in our example\n",
    "\n",
    "        #if the i == [1] --> Female\n",
    "        elif (i == [2]):\n",
    "            container[j,:] = [0,1] #represents Male in our example\n",
    "\n",
    "        #increment the index  for new assigning\n",
    "        j += 1\n",
    "        \n",
    "    \n",
    "    #left-concatenation \n",
    "    left_concatenation = np.concatenate((left,container), axis = 1)\n",
    "    \n",
    "    #right-concatenation --> (left + right)\n",
    "    right_concatenation = np.concatenate((left_concatenation,right), axis = 1)\n",
    "    \n",
    "    #assign the concatenated parts to one_hot\n",
    "    one_hot = right_concatenation\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.kMeans()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = \"font-size: 18px\" >The Algorithm\n",
    "In the clustering problem, we are given a training set ${x^{(1)}, ... , x^{(m)}}$, and want to group the data into a few cohesive \"clusters.\" Here, we are given feature vectors for each data point $x^{(i)} \\in \\mathbb{R}^n$ as usual; but no labels $y^{(i)}$ (making this an unsupervised learning problem). Our goal is to predict $k$ centroids and a label $c^{(i)}$ for each datapoint. The k-means clustering algorithm is as follows: </p>\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "<img src = \"https://i.imgur.com/BWipiBC.png\" >\n",
    "\n",
    "\n",
    "### Note:\n",
    "The K-means\n",
    "algorithm will always converge to some final set of means for the centroids.\n",
    "Note that the converged solution may not always be ideal and depends on the\n",
    "initial setting of the centroids. Therefore, in practice the K-means algorithm\n",
    "is usually run a few times with different random initializations. One way to\n",
    "choose between these different solutions from different random initializations\n",
    "is to choose the one with the lowest cost function value (distortion).\n",
    "\n",
    "In other words choose $\\large c^{(i)} := j$  that minimizes $\\large ||x^{(i)} − µ_{j}||^2$\n",
    "\n",
    "<strong>where,</strong>\n",
    "<br>\n",
    "$\\normalsize c_{i}:$ is the index of the centroid that is closest to $\\normalsize x^{(i)}$\n",
    "\n",
    "$ \\normalsize\\mu_{j}:$ is the position (value) of the j’th centroid.\n",
    "\n",
    "<strong>Note that</strong> $\\normalsize c^{(i)}$ corresponds to $\\normalsize idx(i)$\n",
    "\n",
    "<strong>The distortion function is defined as :</strong>\n",
    "\n",
    "<img src = \"https://www.saedsayad.com/images/Clustering_kmeans_c.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeans(X,K,iterations):\n",
    "    '''\n",
    "    Usage:\n",
    "      #kMeans --> used for implementing the K-means clustering algorithm\n",
    "  \n",
    "    Arguments:\n",
    "      #X --> The Design(data) Matrix\n",
    "      #K --> the total number of centroids\n",
    "      #iterations --> the number of iterations needed to get the optimal centorids \n",
    "    \n",
    "    Returns:\n",
    "      #idx --> a one-dimensional array, idx, that holds the index (a value in {1,....,K} \n",
    "               where K is total number of centroids) of the closest centroid \n",
    "               to every training example.\n",
    "      #centroids --> the optimal centroids by computing the means of\n",
    "                     the data points assigned to each centroid  \n",
    "    '''\n",
    "    \n",
    "    #Initialize centroids\n",
    "    centroids = kMeansInitCentroids(X,K)\n",
    "    \n",
    "    #Keep until convergance \n",
    "    for iteration in range(iterations):\n",
    "        \n",
    "        #helper to observe in which iteration we are\n",
    "        print(\"K-Means iteration {}/{}...\".format(iteration, iterations - 1))\n",
    "        \n",
    "        #Cluster assignment step: Assign each data point to the\n",
    "        #closest centroid. idx(i) corresponds to cˆ(i), the index\n",
    "        #of the centroid assigned to example i\n",
    "        idx = findClosestCentroids(X,centroids)\n",
    "        \n",
    "        #Move centroid step: Compute means based on centroid assignments\n",
    "        centroids = computeCentroids(X,idx,K)\n",
    "    \n",
    "    print(\"\\n\\nThe Model has been trained\\n\\n\")\n",
    "        \n",
    "        \n",
    "    return idx, centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.lowestCost()\n",
    "\n",
    "<br>\n",
    "\n",
    "## reminder\n",
    "\n",
    "in practice the K-means algorithm is usually run a few times with different random initializations. One way to choose between these different solutions from different random initializations is to choose the one with the lowest cost function value (distortion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowestCost(X,K,iterations,init_num):\n",
    "    '''\n",
    "    Usage:\n",
    "      #kMeans --> For computing the lowest cost corresponding to a specific centroids\n",
    "  \n",
    "    Arguments:\n",
    "      #X --> The Design(data) Matrix\n",
    "      #K --> the total number of centroids\n",
    "      #iterations -->  the number of iterations needed to get the optimal centorids\n",
    "      #init_num --> the number of intializations of centroids needed to get the optimal centorids \n",
    "    \n",
    "    Returns:\n",
    "      #Cost --> array holds all the cost values at different random intializations\n",
    "      #dic --> a dictionary the key is the index of the a specific cost at a random initialization\n",
    "              and the value is (idx,centroid) pair\n",
    "      #lowest_cost --> the lowest cost corresponding to a specific centroids\n",
    "      \n",
    "      #idx_lowest_cost --> index of the lowest cost\n",
    "      \n",
    "      \n",
    "    #Notes:\n",
    "     1.from the idx_lowset_cost we can get the (idx,centroids) corresponding to the lowest cost\n",
    "       using --> (dic)\n",
    "    '''\n",
    "    \n",
    "    #pre-allocating empty-dic and its key will be the index of the cost \n",
    "    #and the value will be (idx,centroids) pair correponding to this cost\n",
    "    dic = {}\n",
    "    \n",
    "    #Define a container to hold all the values of the cost for different initialization\n",
    "    cost = np.zeros((init_num,))\n",
    "    \n",
    "    for r in range(init_num):\n",
    "        #Track the initialization number \n",
    "        print(\"At initialization number: {}\\n\\n\".format(r))\n",
    "        \n",
    "        #compute idx,centroids for at a random initialization \n",
    "        idx,centroids= kMeans(X,K,iterations)\n",
    "        \n",
    "        #iterating over the training examples to compute the cost \n",
    "        for i in range(X.shape[0]):\n",
    "            #incement the cost r so at the end of the iteration r we get the overall value of cost r\n",
    "            cost[r] += np.power(np.linalg.norm(X[i] - centroids[idx[i]]),2)\n",
    "        \n",
    "        #Store the (idx,centroids) pair corresponding to the cost r\n",
    "        dic[r] = (idx,centroids)\n",
    "            \n",
    "    \n",
    "    #get the lowest cost \n",
    "    lowest_cost = np.min(cost, axis = 0)\n",
    "    \n",
    "    #get the index of the lowest cost\n",
    "    idx_lowest_cost = np.argmin(cost, axis = 0)\n",
    "    \n",
    "    \n",
    "    return cost,dic,lowest_cost,idx_lowest_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#Define the training set#\n",
    "#########################\n",
    "\n",
    "#Define the left-encoded part\n",
    "left =X[:,0].reshape(200,1)\n",
    "\n",
    "#Define the Un-encoded part\n",
    "unencoded = X[:,1].reshape(200,1)\n",
    "\n",
    "\n",
    "#Dfine the right-encoded part \n",
    "right = X[:,2:]\n",
    "\n",
    "#Define the concatenated-encoded parts --> Training set\n",
    "X_train = oneHot(left,unencoded,right,width = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the training examples after encoding \n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the shape of the training examples after encoding \n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx, centroids = kMeans(X = X_train,K = 5,iterations = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visulaize the 5-distinct groups\n",
    "plt.scatter(X_train[:,-2], X_train[:,-1],color = 'r')\n",
    "plt.scatter(centroids[:,-2], centroids[:,-1] ,color = 'b')\n",
    "\n",
    "plt.xlabel(\"Annual Income (k$)\")\n",
    "plt.ylabel(\"Spending Score (1-100)\")\n",
    "plt.title(\"The relation between Spending Score and Annual Income\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "<p style = \"font-size:18px\"><strong>in practise,</strong> we need to run the algorithm for different random initializations to get the optimal centroids </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the optimal centroids\n",
    "cost,dic,lowest_cost,idx_lowest_cost = lowestCost(X_train,K = 5,iterations = 1000,init_num = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the cost values at different initializations\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the lowest cost \n",
    "lowest_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the index of the lowest cost \n",
    "idx_lowest_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the index of the closest centroid to every training example, and the optimal centroids\n",
    "idx,centroids = dic[idx_lowest_cost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the index\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the optimal centroids\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visulaize the 5-distinct groups\n",
    "plt.scatter(X_train[:,-2], X_train[:,-1],color = 'r',label = \"Data Points\")\n",
    "plt.scatter(centroids[:,-2], centroids[:,-1] ,color = 'b',label = \"Centroids\")\n",
    "plt.xlabel(\"Annual Income (k$)\")\n",
    "plt.ylabel(\"Spending Score (1-100)\")\n",
    "plt.title(\"The relation between Spending Score and Annual Income\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
