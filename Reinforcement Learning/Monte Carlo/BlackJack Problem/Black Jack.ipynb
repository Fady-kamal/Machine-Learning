{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Monte Carlo Method ?\n",
    "\n",
    "It's a method of estimating the value function by taking the mean return instead of the expected return.The Monte Carlo method for reinforcement learning learns directly from episodes of experience without any prior knowledge of MDP transitions.But how we can solve the MDP withount any prior knowledge of MDP transitions ? The idea based on the law of the large numbers.\n",
    "\n",
    "\n",
    "#### Recall, \n",
    "\n",
    "\\begin{equation}\n",
    "\\large\n",
    "V^{\\pi}(S_{t} = s) = \\operatorname{\\mathbb{E}}[G_{t} | S_{t} = s]\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "<strong>By the law of large numbers,</strong> integrals described by the expected value of some random variable can be approximated by taking the empirical mean.so we can take the mean of the return rather than the expected value, and therefore we can solve the problem without any knowledge of MDP.\n",
    "\n",
    "# What is Black Jack Game ?\n",
    "\n",
    "<img src = \"https://i.imgur.com/jCD3ciR.jpg\" >\n",
    "\n",
    "* Blackjack is a card game that pits player versus dealer. \n",
    "\n",
    "\n",
    "* It is played with one or more decks of cards. \n",
    "\n",
    "\n",
    "* Cards are counted as their respective numbers, face cards as ten, and ace as either eleven or one (in our game it will show on the counter as an 11 unless you are over 21). \n",
    "\n",
    "\n",
    "\n",
    "* The object of Blackjack is the beat the dealer. This can be accomplished by getting Blackjack (first two cards equal 21) without dealer Blackjack, having your final card count be higher than the dealers without exceeding 21, or by not exceeding 21 and dealer busting by exceeding their card count of 21.\n",
    "\n",
    "\n",
    "\n",
    "* The Black Jack games is a type of episodic tasks since it has terminal state \n",
    "  when the agent wins or loses. \n",
    "\n",
    "<br>\n",
    "\n",
    "## Notes:\n",
    "* The player has to decide the value of an ace. If the player's sum of cards is 10 and the player\n",
    "  gets an ace after a hit, he can consider it as 11, and 10 + 11 = 21. But if the player's sum of\n",
    "  cards is 15 and the player gets an ace after a hit,if he considers it as 11 and 15+11 = 26, then\n",
    "  it's a bust.\n",
    "  \n",
    "\n",
    "*  If the player has an ace we can call it <strong>a usable ace;</strong> the player can consider it as 11 without being bust. \n",
    "\n",
    "\n",
    "\n",
    "* If the player is bust by considering the ace as 11, then it is called\n",
    "<strong> nonusable ace.</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Rewards in The Game: \n",
    "\n",
    "* $+1 :$ if the player win the game\n",
    "* $-1 :$ if the player loses the game\n",
    "* $\\hspace{1.5mm}0\\hspace{1.5mm}:$ if the game is a draw \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "## The Actions in The Game:\n",
    "\n",
    "* <strong>Hit :</strong> if the player needs a card\n",
    "* <strong>Stand:</strong> if the player doesn't need a card\n",
    "\n",
    "<br>\n",
    "\n",
    "## The Observations in The Game:\n",
    "The observation of a 3-tuple of: \n",
    "* The player's current sum\n",
    "* The dealer's one showing card (1-10 where 1 is ace),\n",
    "* A Boolean Value represents  whether or not the player holds a usable ace (0 or 1).\n",
    "\n",
    "## The agent-enivronment interaction \n",
    "\n",
    "<img src = \"https://gym.openai.com/assets/docs/aeloop-138c89d44114492fd02822303e6b4b07213010bb14ca5856d2d49d6b62d88e53.svg\" >\n",
    "\n",
    "The agent and the environment interact at each of a sequence of discrete time steps $t = 0,1,2,\\ldots.$ Each timestep, the agent chooses an action, and the environment returns an observation and a reward.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<strong>Now,</strong> we are going to solve Black Jack problem using First Visit Monte Carlo Method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary items \n",
    "import gym \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-08-26 15:02:14,618] Making new env: Blackjack-v0\n",
      "C:\\Users\\FADY-PC\\anaconda3\\lib\\site-packages\\gym\\envs\\registration.py:18: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "#Create the Blackjack environment using OpenAI's Gym \n",
    "env = gym.make('Blackjack-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_policy(observation):\n",
    "    '''\n",
    "    Usage:\n",
    "      #sample_policy --> used to perform an action based on the agent's score\n",
    "  \n",
    "    Arguments:\n",
    "      #observation --> represents the current state\n",
    "    \n",
    "    Returns:\n",
    "      #0 --> if the score >= 20 (stand)\n",
    "      #1 --> otherwise (hit)\n",
    "      \n",
    "    '''\n",
    "    \n",
    "    score, dealer_score, usable_ace = observation \n",
    "    \n",
    "    return 0 if score >= 20 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_episode(policy, env):\n",
    "    '''\n",
    "    Usage:\n",
    "      #generate_episode --> used to generate an episode which is a single round of a game\n",
    "  \n",
    "    Arguments:\n",
    "      #policy --> reprensents the way to behave (perform an action) at a certain state \n",
    "      #env --> represents the environment that the agent interact with\n",
    "    \n",
    "    Returns:\n",
    "      #states --> the states we reached during the interaction between the agent and environment\n",
    "      \n",
    "      #rewards --> the reward the agent got as a result of the interaction between \n",
    "                   the agent and environment   \n",
    "                   \n",
    "      #actions --> the actions that the agent performed during the interaction \n",
    "                   between the agent and environment\n",
    "    \n",
    "    Notes:\n",
    "     #Each timestep, the agent chooses an action, and the environment returns \n",
    "      an observation and a reward.The process gets started by calling reset(),\n",
    "      which returns an initial observation\n",
    "      \n",
    "    '''\n",
    "    \n",
    "    #First, define states,actions,rewards as empty list \n",
    "    states, actions, rewards = [], [], []\n",
    "    \n",
    "    \n",
    "    #Second, initiate the environment using env.reset()\n",
    "    observation = env.reset()\n",
    "    \n",
    "    #At the end of every episode , we do the following\n",
    "    while True:\n",
    "        \n",
    "        #1-Append the observation to the states list\n",
    "        states.append(observation)\n",
    "        \n",
    "        #2-Create an action using sample_policy function, and append the action to action list\n",
    "        action = sample_policy(observation)\n",
    "        actions.append(action)\n",
    "        \n",
    "        #3-Each timestep, the agent chooses an action, and \n",
    "        #the environment returns an observation and a reward.\n",
    "        #so we will return observation,reward, info(dict for diagnostic information useful for debugging)\n",
    "        #Also, we return, done --> which is a flag used to check if we reached terminal state or not\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        rewards.append(reward)\n",
    "        \n",
    "        #if we reached the terminal state, then we break \n",
    "        if done: \n",
    "            break\n",
    "            \n",
    "    return states, actions, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_visit_mc_prediction(policy, env, n_episodes):\n",
    "    '''\n",
    "    Usage:\n",
    "      #first_visit_mc_predicition --> used to aproximate the value function using \n",
    "                                      First Visit Monte Carlo  Method\n",
    "  \n",
    "    Arguments:\n",
    "      #policy --> reprensents the way to behave (perform an action) at a certain state \n",
    "      #env --> represents the environment that the agent interact with\n",
    "      #n_episodes --> the number of episodes\n",
    "    \n",
    "    Returns:\n",
    "      #value_table --> represents the approximated value of the value function for every state\n",
    "      \n",
    "    '''\n",
    "    \n",
    "    #Define empty value table as a dic for storing the values at each state\n",
    "    value_table = defaultdict(float)\n",
    "    \n",
    "    #Initialize N(S) as dic for storing the every state (keys) , and \n",
    "    #the number of times we visit every state (Values)\n",
    "    N = defaultdict(int)\n",
    "    \n",
    "    #For a ceatrain number of episodes , we do the following \n",
    "    for episode in range(n_episodes):\n",
    "        \n",
    "        #1-generate an episode and store the result (states, and rewards)\n",
    "        states, _, rewards = generate_episode(policy, env)\n",
    "        \n",
    "        #2-initialize the return  (sum of the rewards)\n",
    "        G = 0\n",
    "\n",
    "        #3-Each time step of an episode, we store the reward to R and state to S obtained \n",
    "        #from the choosen action, Then we calcuatle the return as a sum of the reward\n",
    "        for t in range(len(states) - 1, -1, -1):\n",
    "            R = rewards[t]\n",
    "            S = states[t]\n",
    "            G += R\n",
    "            \n",
    "            #Apply First Visit Monte Carlo Method\n",
    "            #check if that is the first time the state is visited in an episode\n",
    "            if S not in states[:t]:\n",
    "                #increment N(S)\n",
    "                N[S] += 1\n",
    "                #Estimated the value function of a state by mean return\n",
    "                value_table[S] += G / N[S]\n",
    "                \n",
    "    return value_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing The Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the approximated value function for all states\n",
    "value = first_visit_mc_prediction(sample_policy, env, n_episodes=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {(20, 10, False): 5.452824238110242,\n",
       "             (19, 10, False): -6.687224264614749,\n",
       "             (19, 1, False): -7.478889808807915,\n",
       "             (17, 1, False): -7.507231463335668,\n",
       "             (11, 1, False): -3.443660816827226,\n",
       "             (18, 10, False): -7.922466907095889,\n",
       "             (14, 10, False): -6.84847558632649,\n",
       "             (19, 7, False): -7.591882026271605,\n",
       "             (12, 7, False): -5.840202634774576,\n",
       "             (16, 5, False): -6.7015653422770605,\n",
       "             (16, 5, True): -3.7774017490359,\n",
       "             (15, 5, True): -2.7516882813377896,\n",
       "             (18, 2, False): -7.331498171677159,\n",
       "             (8, 2, False): -4.784198340535718,\n",
       "             (4, 2, False): -4.098782965125565,\n",
       "             (11, 7, False): -1.8791069126891629,\n",
       "             (21, 2, False): 7.609305321171586,\n",
       "             (17, 2, False): -4.947870175713576,\n",
       "             (16, 10, False): -5.882068263123497,\n",
       "             (19, 9, False): -6.895629475405596,\n",
       "             (19, 9, True): -3.14927028057665,\n",
       "             (16, 1, False): -7.0597432178810875,\n",
       "             (19, 6, False): -6.290328101617755,\n",
       "             (13, 6, False): -6.017897890398651,\n",
       "             (5, 6, False): -3.6783803215965847,\n",
       "             (17, 8, False): -7.159585221348235,\n",
       "             (12, 5, False): -4.517911772572094,\n",
       "             (10, 5, False): -2.5389661466633444,\n",
       "             (7, 5, False): -3.133846592327515,\n",
       "             (15, 10, False): -5.822580137003303,\n",
       "             (20, 2, False): 4.306051399987661,\n",
       "             (21, 10, False): 9.024255054867737,\n",
       "             (10, 2, False): -1.6852627359250898,\n",
       "             (17, 3, False): -6.703479006190945,\n",
       "             (16, 4, False): -5.99392958105987,\n",
       "             (18, 4, True): -3.0528796459770287,\n",
       "             (20, 3, False): 4.348335828925162,\n",
       "             (18, 3, False): -7.107208924249736,\n",
       "             (19, 8, False): -6.649216679817601,\n",
       "             (13, 8, False): -6.2564204631874505,\n",
       "             (17, 9, False): -6.97119233993093,\n",
       "             (16, 9, False): -6.980604092455357,\n",
       "             (14, 9, False): -6.111621248879081,\n",
       "             (14, 9, True): -3.4828951925954996,\n",
       "             (18, 4, False): -6.7966236194656515,\n",
       "             (9, 9, False): -4.7223391004241675,\n",
       "             (12, 10, False): -4.48405853609895,\n",
       "             (11, 10, False): 0.49279147604454504,\n",
       "             (20, 9, False): 8.01445564604269,\n",
       "             (13, 9, False): -2.8240562471777193,\n",
       "             (10, 9, False): 0.12178912057194384,\n",
       "             (15, 8, False): -6.050218757255547,\n",
       "             (20, 7, False): 4.341526837910083,\n",
       "             (20, 1, False): 3.158227374323364,\n",
       "             (15, 1, False): -4.604729853414304,\n",
       "             (13, 1, False): -3.6082443821237296,\n",
       "             (18, 6, False): -7.2134253644610205,\n",
       "             (11, 6, False): -1.187574664131225,\n",
       "             (13, 6, True): -0.9018664996935928,\n",
       "             (19, 5, False): -7.372158659024539,\n",
       "             (21, 5, True): 7.701909334020681,\n",
       "             (21, 3, True): 7.663656714940982,\n",
       "             (21, 5, False): 8.191260568596581,\n",
       "             (11, 5, False): 0.379150072453982,\n",
       "             (16, 2, False): -6.006908573277631,\n",
       "             (13, 2, False): -5.833439949114405,\n",
       "             (14, 8, False): -6.0512434688825305,\n",
       "             (21, 6, True): 7.627352941316176,\n",
       "             (20, 6, False): 6.803039978533528,\n",
       "             (17, 10, True): -4.854312997959067,\n",
       "             (5, 10, False): -5.309509932869931,\n",
       "             (17, 1, True): -4.182371476167332,\n",
       "             (21, 8, False): 7.774299659570258,\n",
       "             (12, 8, False): -3.7471221134499775,\n",
       "             (10, 8, False): 0.14833915450320226,\n",
       "             (14, 5, False): -3.885833485440695,\n",
       "             (18, 9, True): -4.355161674428647,\n",
       "             (17, 9, True): -2.639027614539276,\n",
       "             (15, 9, True): -2.945110230784905,\n",
       "             (21, 6, False): 7.727952427160855,\n",
       "             (13, 10, False): -6.1428158145541225,\n",
       "             (10, 10, False): -2.3603463954163986,\n",
       "             (20, 8, True): 5.3226465179361755,\n",
       "             (15, 9, False): -5.9453490841765335,\n",
       "             (17, 7, False): -6.295015804102682,\n",
       "             (19, 3, False): -5.996118427462056,\n",
       "             (12, 2, False): -5.098110433517115,\n",
       "             (18, 9, False): -6.954224262077994,\n",
       "             (21, 10, True): 8.660655220988323,\n",
       "             (18, 7, False): -7.26307190108779,\n",
       "             (16, 7, False): -6.6781452729126185,\n",
       "             (10, 6, False): -2.488040622537725,\n",
       "             (6, 6, False): -3.46391801662916,\n",
       "             (8, 9, False): -4.660941892486997,\n",
       "             (20, 5, False): 6.966243189173791,\n",
       "             (20, 1, True): 2.695230824958294,\n",
       "             (8, 7, False): -4.323029958239518,\n",
       "             (9, 5, False): -5.251083658720074,\n",
       "             (21, 9, False): 8.47599234216295,\n",
       "             (12, 9, False): -3.3442126243221333,\n",
       "             (15, 2, False): -5.4058215961234,\n",
       "             (15, 2, True): -2.5309072064892444,\n",
       "             (17, 5, False): -5.629592100640035,\n",
       "             (21, 1, True): 5.1155322828875684,\n",
       "             (14, 1, False): -7.268693366886045,\n",
       "             (15, 5, False): -3.7216006726374182,\n",
       "             (7, 9, False): -3.7338880678258306,\n",
       "             (9, 10, False): -5.5422517985343385,\n",
       "             (17, 10, False): -8.003494725910716,\n",
       "             (12, 6, False): -5.671067406841988,\n",
       "             (13, 4, False): -5.658667674412296,\n",
       "             (12, 4, True): -2.7518911160828634,\n",
       "             (15, 6, False): -6.667434889557611,\n",
       "             (7, 6, False): -4.2755719366407705,\n",
       "             (13, 5, False): -5.983745831075131,\n",
       "             (15, 4, False): -5.800469764019594,\n",
       "             (14, 3, False): -6.5511467452997465,\n",
       "             (14, 4, False): -4.126851919936271,\n",
       "             (16, 6, False): -5.837786245656922,\n",
       "             (21, 7, False): 8.468984454728833,\n",
       "             (7, 7, False): -3.0778573545626986,\n",
       "             (20, 5, True): 2.9119591960455344,\n",
       "             (19, 2, False): -7.3246106654857055,\n",
       "             (9, 2, False): -4.688252288986317,\n",
       "             (21, 4, True): 7.4796498173576085,\n",
       "             (12, 4, False): -6.156515394532294,\n",
       "             (21, 1, False): 4.554912562691088,\n",
       "             (12, 1, False): -4.299997181688856,\n",
       "             (18, 5, False): -6.771239065446376,\n",
       "             (6, 10, False): -3.463066262741453,\n",
       "             (14, 7, False): -5.776773257961306,\n",
       "             (18, 1, False): -7.4039154401005725,\n",
       "             (9, 3, False): -2.917183257759933,\n",
       "             (14, 6, False): -5.2343478405260795,\n",
       "             (7, 10, False): -3.840234840553443,\n",
       "             (21, 4, False): 7.972043280842775,\n",
       "             (16, 3, False): -6.378625831698677,\n",
       "             (15, 3, False): -6.721084738328592,\n",
       "             (19, 10, True): -3.7896580631481736,\n",
       "             (8, 6, False): -4.834968701038595,\n",
       "             (16, 10, True): -4.63575234011441,\n",
       "             (13, 10, True): -3.9579220596090994,\n",
       "             (17, 4, False): -4.671568443683394,\n",
       "             (18, 7, True): -3.527780961342414,\n",
       "             (20, 8, False): 7.850296663333542,\n",
       "             (11, 3, False): -1.8548719487128238,\n",
       "             (15, 7, False): -3.9781574059686364,\n",
       "             (10, 3, False): 0.38320357401893673,\n",
       "             (12, 3, False): -4.61306475575371,\n",
       "             (10, 1, False): -3.9050045149785033,\n",
       "             (18, 8, False): -6.788930319438768,\n",
       "             (7, 8, False): -4.907449694328381,\n",
       "             (19, 3, True): -2.5424198297812213,\n",
       "             (13, 3, False): -4.890892949904766,\n",
       "             (5, 7, False): -4.501013642627216,\n",
       "             (20, 9, True): 4.291998013416737,\n",
       "             (17, 5, True): -3.7569863448585687,\n",
       "             (14, 2, False): -5.925183545586655,\n",
       "             (11, 2, False): -1.4738047275308448,\n",
       "             (7, 2, False): -5.160676395039405,\n",
       "             (18, 3, True): -3.6457059355627877,\n",
       "             (12, 3, True): -1.7361252574646253,\n",
       "             (20, 10, True): 3.9397520006631095,\n",
       "             (19, 4, False): -7.659762417141962,\n",
       "             (11, 4, False): -1.7726511707091692,\n",
       "             (21, 8, True): 8.06449902105659,\n",
       "             (5, 1, False): -3.220090108077978,\n",
       "             (20, 4, False): 7.191529333345328,\n",
       "             (9, 7, False): -4.652938672678257,\n",
       "             (8, 4, False): -4.615063659370985,\n",
       "             (11, 9, False): -0.894022314660206,\n",
       "             (16, 3, True): -3.546279864851541,\n",
       "             (20, 3, True): 5.462938496265803,\n",
       "             (8, 1, False): -5.75391741976998,\n",
       "             (10, 7, False): -0.051895861644346515,\n",
       "             (20, 4, True): 5.055406746717201,\n",
       "             (14, 4, True): -1.121252931821576,\n",
       "             (19, 7, True): -4.554860088886896,\n",
       "             (18, 10, True): -5.91189956684771,\n",
       "             (9, 8, False): -3.5230862065251407,\n",
       "             (13, 7, False): -5.095271137928566,\n",
       "             (6, 7, False): -3.7161044041417655,\n",
       "             (5, 2, False): -4.5416944003877155,\n",
       "             (21, 9, True): 8.115206789500583,\n",
       "             (14, 10, True): -3.4454448600100442,\n",
       "             (4, 10, False): -4.964081426097695,\n",
       "             (20, 7, True): 6.166222448842512,\n",
       "             (17, 7, True): -0.63742411412262,\n",
       "             (12, 7, True): 0.47717498585637524,\n",
       "             (7, 3, False): -5.205918351577063,\n",
       "             (4, 3, False): -2.602088358041689,\n",
       "             (7, 1, False): -5.190861351445553,\n",
       "             (16, 8, False): -4.921683142553153,\n",
       "             (16, 9, True): -4.330161482968533,\n",
       "             (15, 10, True): -4.124278934409928,\n",
       "             (12, 10, True): -3.6286744049396713,\n",
       "             (17, 6, True): -3.4996096690668406,\n",
       "             (16, 6, True): -3.544899567483103,\n",
       "             (9, 1, False): -4.822460711671941,\n",
       "             (17, 8, True): -2.7363750440997943,\n",
       "             (18, 2, True): -3.3384319583706614,\n",
       "             (13, 9, True): -0.31627772525225434,\n",
       "             (17, 6, False): -6.431385449643044,\n",
       "             (21, 2, True): 7.559666881194123,\n",
       "             (18, 8, True): -2.524562453060642,\n",
       "             (14, 7, True): -2.5551259597243012,\n",
       "             (21, 3, False): 7.888750314082513,\n",
       "             (21, 7, True): 7.76002197505614,\n",
       "             (20, 2, True): 5.7047775096179505,\n",
       "             (17, 2, True): -1.4301065849713013,\n",
       "             (16, 2, True): -1.9030849633793856,\n",
       "             (9, 4, False): -5.004139634785015,\n",
       "             (19, 4, True): -4.149007136967313,\n",
       "             (13, 4, True): -1.755805848513129,\n",
       "             (15, 4, True): -2.737419388720074,\n",
       "             (11, 8, False): 1.3199623770782658,\n",
       "             (19, 6, True): -4.867140138048861,\n",
       "             (18, 6, True): -3.4745025939423027,\n",
       "             (6, 3, False): -4.547200565847216,\n",
       "             (12, 2, True): -1.3507366922500974,\n",
       "             (8, 10, False): -3.598752082968002,\n",
       "             (6, 2, False): -0.49666226011665987,\n",
       "             (5, 8, False): -3.6978761186021782,\n",
       "             (8, 5, False): -5.585706651755976,\n",
       "             (18, 5, True): -4.668256703237821,\n",
       "             (19, 5, True): -2.382954029320119,\n",
       "             (14, 5, True): 0.9694636540062742,\n",
       "             (19, 8, True): -3.031939526939409,\n",
       "             (17, 3, True): -2.2594620691258296,\n",
       "             (5, 9, False): -2.969122200751471,\n",
       "             (16, 4, True): -3.8160624627493207,\n",
       "             (19, 2, True): -2.5343360825585,\n",
       "             (16, 7, True): -3.0451168405187135,\n",
       "             (13, 7, True): -1.7690320996973645,\n",
       "             (10, 4, False): -2.8437962130540884,\n",
       "             (14, 6, True): -3.4156888926254556,\n",
       "             (15, 1, True): -2.5415111022751176,\n",
       "             (15, 6, True): -3.4945913673926827,\n",
       "             (8, 3, False): -5.427620180997004,\n",
       "             (20, 6, True): 5.812211936748527,\n",
       "             (9, 6, False): -1.021979922773915,\n",
       "             (13, 3, True): -1.71370245392225,\n",
       "             (6, 8, False): -4.410574784505778,\n",
       "             (5, 5, False): -4.76016511078596,\n",
       "             (15, 3, True): -2.756785212044142,\n",
       "             (12, 8, True): -2.3989219516229436,\n",
       "             (4, 7, False): -0.5296787431895559,\n",
       "             (14, 1, True): -3.812680739163357,\n",
       "             (6, 4, False): -4.478283605871444,\n",
       "             (16, 8, True): -3.953635442514786,\n",
       "             (13, 1, True): -2.4708595442651617,\n",
       "             (8, 8, False): -3.948709303150049,\n",
       "             (16, 1, True): -4.022189279138135,\n",
       "             (15, 7, True): -1.8163784730558947,\n",
       "             (7, 4, False): -1.7476825815506423,\n",
       "             (14, 3, True): -0.7553109546336411,\n",
       "             (18, 1, True): -4.1342440024942695,\n",
       "             (6, 9, False): -4.875681393288665,\n",
       "             (13, 2, True): -0.33069759866703663,\n",
       "             (6, 1, False): -5.5868807176180955,\n",
       "             (6, 5, False): -4.947793860483782,\n",
       "             (17, 4, True): -3.0846418601998984,\n",
       "             (19, 1, True): -3.974449207047035,\n",
       "             (4, 5, False): -4.151103535998934,\n",
       "             (15, 8, True): -3.504316346035044,\n",
       "             (13, 5, True): -1.425772644904426,\n",
       "             (12, 6, True): -0.5872163140288709,\n",
       "             (12, 5, True): -1.0249447195067776,\n",
       "             (5, 3, False): -3.9242946308960316,\n",
       "             (14, 2, True): -3.2608070271961815,\n",
       "             (4, 4, False): -3.3620141939193497,\n",
       "             (14, 8, True): -3.3024865768244136,\n",
       "             (12, 1, True): -1.901253772125688,\n",
       "             (5, 4, False): -2.8716945426900433,\n",
       "             (13, 8, True): -2.722138236169886,\n",
       "             (4, 8, False): -1.3106352832570782,\n",
       "             (4, 9, False): -1.9341987871290613,\n",
       "             (12, 9, True): -0.7752068717988189,\n",
       "             (4, 6, False): -3.3492011422264985,\n",
       "             (4, 1, False): -4.025815976041375})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explore the value for all states\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
